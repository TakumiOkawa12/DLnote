{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ab236d-0a06-48f0-8c80-3101b385b300",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec2a018-e8b9-4a3a-92ea-782c03e97980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff682e86-3e83-4599-ba8c-38fbc4dfce4a",
   "metadata": {},
   "source": [
    "### Bakwardをスクラッチで実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6180124-bf1e-4a49-8bcb-66b80b77c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(A, W, b, Z):\n",
    "    W.grad_ = Z.grad_.T @ A\n",
    "    b.grad_ = torch.sum(Z.grad_, dim=0) # バイアス項は全てのデータに加算される形になるので，逆伝播時には集約する\n",
    "    A.grad_ = Z.grad_ @ W\n",
    "    \n",
    "def relu_backward(Z, A):\n",
    "    # 入力が正なら1(True)として，負なら0(False), それぞれの要素をマスクする\n",
    "    Z.grad_ = A.grad_ * (Z>0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4440b666-c2f7-4927-a08b-33a38b2e3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmaxとcrossentropyを同じ関数にする（する必要はないが，pytorchの実装に合わせている\n",
    "def softmax_cross_entropy(x, y_true):\n",
    "    e_x = torch.exp(x - torch.max(x, dim=-1, keepdim=True)[0])\n",
    "    softmax_out =  e_x / (torch.sum(e_x, dim=-1, keepdim=True) + 1e-10)\n",
    "    loss = -torch.sum(y_true * torch.log(softmax_out + 1e-10)) / y_true.shape[0]\n",
    "    return loss, softmax_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bdea0e8-6c88-45cc-ab77-5cab2bb16340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(X, W, b):\n",
    "    return X@W.T + b\n",
    "def relu(Z):\n",
    "    return Z.clamp_min(0.)\n",
    "def forward_and_backward(X, y):\n",
    "    # forward\n",
    "    Z1 = linear(X, W1, b1)\n",
    "    Z1.retain_grad()\n",
    "    A1 = relu(Z1)\n",
    "    A1.retain_grad()\n",
    "    Z2 = linear(A1, W2, b2)\n",
    "    Z2.retain_grad()\n",
    "    loss, A2 = softmax_cross_entropy(Z2, y)\n",
    "\n",
    "    # backward\n",
    "    Z2.grad_ = (A2 - y) / X.shape[0]\n",
    "    linear_backward(A1, W2, b2, Z2)\n",
    "    relu_backward(Z1, A1)\n",
    "    linear_backward(X, W1, b1, Z1)\n",
    "    return loss, Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13dfafe-8f1b-437b-8964-44676aae3802",
   "metadata": {},
   "source": [
    "### Autogradの結果と一致することを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "537c4490-867b-4f29-b42e-59d455a21038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 8, 8) (1437,)\n",
      "(360, 8, 8) (360,)\n"
     ]
    }
   ],
   "source": [
    "# 1. データロード\n",
    "dataset = datasets.load_digits()\n",
    "images = dataset['images']\n",
    "target = dataset['target']\n",
    "\n",
    "# 学習データと検証データ分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "# 前処理\n",
    "# 2-1.ラベルのone-hot encoing\n",
    "y_train = F.one_hot(torch.tensor(y_train), num_classes=10)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).reshape(-1, 64)\n",
    "\n",
    "y_val = F.one_hot(torch.tensor(y_val), num_classes=10)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).reshape(-1, 64)\n",
    "\n",
    "# 2-2. 画像の標準化\n",
    "X_train_mean = X_train.mean()\n",
    "X_train_std = X_train.std()\n",
    "X_train = (X_train - X_train_mean) / X_train_std\n",
    "X_val = (X_val - X_train_mean) / X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d03c446d-fce6-429e-9144-ebd427ce54da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# パラメータの初期化\n",
    "m, n = X_train.shape\n",
    "nh = 30\n",
    "class_num = 10\n",
    "# パラメータの初期化\n",
    "# W1 = torch.randn((nh, n), requires_grad=True) # 出力 x 入力\n",
    "# Kaiming初期化を使って，softmaxの入力が大きくならないようにする\n",
    "W1 = torch.randn((nh, n)) * torch.sqrt(torch.tensor(2./n))\n",
    "W1.requires_grad = True\n",
    "b1 = torch.zeros((1, nh), requires_grad=True) # 1 x nh\n",
    "\n",
    "# W2 = torch.randn((class_num, nh), requires_grad=True) # 出力 x 入力\n",
    "# Kaiming初期化を使って，softmaxの入力が大きくならないようにする\n",
    "W2 = torch.randn((class_num, nh)) * torch.sqrt(torch.tensor(2./nh))\n",
    "W2.requires_grad = True\n",
    "b2 = torch.zeros((1, class_num), requires_grad=True) # 1 x nh\n",
    "# スクラッチのbackward\n",
    "loss, Z1, A1, Z2, A2 = forward_and_backward(X_train, y_train)\n",
    "# PytorchのAutograd\n",
    "loss.backward()\n",
    "\n",
    "# autogradと等しいことを確認\n",
    "print(torch.allclose(W1.grad_, W1.grad))\n",
    "print(torch.allclose(b1.grad_, b1.grad))\n",
    "print(torch.allclose(W2.grad_, W2.grad))\n",
    "print(torch.allclose(b2.grad_, b2.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb041c79-dfe2-47e1-a226-1b7372b45e28",
   "metadata": {},
   "source": [
    "### MLPの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da60e411-dc68-45c4-adab-fea848656edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1: train loss:1.7632564107577007, val loss: 9.643961906433105, val accuracy: 0.2805555462837219\n",
      "epoch: 2: train loss:0.9178932451953491, val loss: 7.689807891845703, val accuracy: 0.3472222089767456\n",
      "epoch: 3: train loss:0.6017374098300934, val loss: 5.329108715057373, val accuracy: 0.46666666865348816\n",
      "epoch: 4: train loss:0.4508847088242571, val loss: 4.637267589569092, val accuracy: 0.5277777910232544\n",
      "epoch: 5: train loss:0.36691469978541136, val loss: 3.3451592922210693, val accuracy: 0.6194444298744202\n",
      "epoch: 6: train loss:0.31218967493623495, val loss: 3.5000224113464355, val accuracy: 0.6277777552604675\n",
      "epoch: 7: train loss:0.27147642833491165, val loss: 3.074402093887329, val accuracy: 0.6555555462837219\n",
      "epoch: 8: train loss:0.24020623679583272, val loss: 2.249772548675537, val accuracy: 0.7416666746139526\n",
      "epoch: 9: train loss:0.21829943979779878, val loss: 2.2529470920562744, val accuracy: 0.7416666746139526\n",
      "epoch: 10: train loss:0.1979048615321517, val loss: 1.9408351182937622, val accuracy: 0.7611111402511597\n",
      "epoch: 11: train loss:0.18555757543072104, val loss: 1.8420860767364502, val accuracy: 0.769444465637207\n",
      "epoch: 12: train loss:0.171725505652527, val loss: 1.4658721685409546, val accuracy: 0.8027777671813965\n",
      "epoch: 13: train loss:0.16108598086672524, val loss: 1.8764961957931519, val accuracy: 0.7777777910232544\n",
      "epoch: 14: train loss:0.15111662012835345, val loss: 1.5268847942352295, val accuracy: 0.7944444417953491\n",
      "epoch: 15: train loss:0.14252908388152719, val loss: 1.4820284843444824, val accuracy: 0.8027777671813965\n",
      "epoch: 16: train loss:0.13490849663503468, val loss: 1.576788306236267, val accuracy: 0.7944444417953491\n",
      "epoch: 17: train loss:0.12847596934686104, val loss: 1.081836462020874, val accuracy: 0.8527777791023254\n",
      "epoch: 18: train loss:0.12277537134165566, val loss: 1.1169538497924805, val accuracy: 0.8527777791023254\n",
      "epoch: 19: train loss:0.11621860601007938, val loss: 1.1288344860076904, val accuracy: 0.8527777791023254\n",
      "epoch: 20: train loss:0.11111778044141829, val loss: 0.9819710850715637, val accuracy: 0.8611111044883728\n",
      "epoch: 21: train loss:0.10710834781639278, val loss: 0.9371978640556335, val accuracy: 0.8722222447395325\n",
      "epoch: 22: train loss:0.103062975142772, val loss: 0.9335234761238098, val accuracy: 0.8777777552604675\n",
      "epoch: 23: train loss:0.09860619258445998, val loss: 0.9586776494979858, val accuracy: 0.8722222447395325\n",
      "epoch: 24: train loss:0.09558915121791263, val loss: 0.8631834387779236, val accuracy: 0.8833333253860474\n",
      "epoch: 25: train loss:0.0923646551867326, val loss: 0.8676635026931763, val accuracy: 0.8833333253860474\n",
      "epoch: 26: train loss:0.08891455126771082, val loss: 0.8521581292152405, val accuracy: 0.8861111402511597\n",
      "epoch: 27: train loss:0.08543115873665859, val loss: 0.9398629069328308, val accuracy: 0.875\n",
      "epoch: 28: train loss:0.08326322313708563, val loss: 0.784248948097229, val accuracy: 0.8972222208976746\n",
      "epoch: 29: train loss:0.07941503248487909, val loss: 0.7038068771362305, val accuracy: 0.8999999761581421\n",
      "epoch: 30: train loss:0.0775165418162942, val loss: 0.7262816429138184, val accuracy: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.03\n",
    "batch_size = 30\n",
    "num_batches = np.ceil(len(y_train) / batch_size).astype(int)\n",
    "loss_log = []\n",
    "# 3. パラメータの初期化\n",
    "# パラメータの初期化\n",
    "W1 = torch.randn((nh, n)) * torch.sqrt(torch.tensor(2./n))\n",
    "W1.requires_grad = True\n",
    "b1 = torch.zeros((1, nh), requires_grad=True) # 1 x nh\n",
    "W2 = torch.randn((class_num, nh)) * torch.sqrt(torch.tensor(2./nh))\n",
    "W2.requires_grad = True\n",
    "b2 = torch.zeros((1, class_num), requires_grad=True) # 1 x nh\n",
    "\n",
    "# ログ\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "# 5. for文で学習ループ作成\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    shuffled_indices = np.random.permutation(len(y_train))\n",
    "    running_loss = 0\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        # mini batch作成\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_indices = shuffled_indices[start:end]\n",
    "        # 6. 入力データXおよび教師ラベルのYを作成\n",
    "        y_true_ = y_train[batch_indices, :] # データ数xクラス数\n",
    "        X = X_train[batch_indices, :] # データ数 x 特徴量数\n",
    "        # import pdb; pdb.set_trace()\n",
    "\n",
    "        # 7. Z計算\n",
    "        # Z = X@W.T + b # -> MLP\n",
    "        Z1 = linear(X, W1, b1)\n",
    "        A1 = relu(Z1)\n",
    "        Z2 = linear(A1, W2, b2)\n",
    "        loss, A2 = softmax_cross_entropy(Z2, y_true_)\n",
    "\n",
    "        # 8. softmaxで予測計算\n",
    "        # y_pred = softmax(Z)\n",
    "\n",
    "        # 9. 損失計算\n",
    "        # loss = cross_entropy(y_true_, y_pred) #-> softmax_cross_entropy\n",
    "        loss_log.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 10. 勾配計算\n",
    "        # loss.backward() # -> scratchのbackward\n",
    "        Z2.grad_ = (A2 - y_true_) / X.shape[0]\n",
    "        linear_backward(A1, W2, b2, Z2)\n",
    "        relu_backward(Z1, A1)\n",
    "        linear_backward(X, W1, b1, Z1)\n",
    "\n",
    "        # 11. パラメータ更新\n",
    "        with torch.no_grad():\n",
    "            W1 -= learning_rate * W1.grad_ # .grad -> .grad_\n",
    "            W2 -= learning_rate * W2.grad_ # .grad -> .grad_\n",
    "            b1 -= learning_rate * b1.grad_\n",
    "            b2 -= learning_rate * b2.grad_\n",
    "\n",
    "        # 12. 勾配初期化\n",
    "        # W.grad.zero_() # .grad_ = None\n",
    "        # b.grad.zero_()\n",
    "            W1.grad_ = None\n",
    "            W2.grad_ = None\n",
    "            b1.grad_ = None\n",
    "            b2.grad_ = None\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        # Z_val = X_val@W.T + b # -> MLP\n",
    "        Z1_val = linear(X_val, W1, b1)\n",
    "        A1_val = relu(Z1_val)\n",
    "        Z2_val = linear(A1_val, W2, b2)\n",
    "        val_loss, A2_val = softmax_cross_entropy(Z2_val, y_val)\n",
    "        # y_pred_val = softmax(Z_val)\n",
    "\n",
    "        # val_loss = cross_entropy(y_val, y_pred_val) #-> softmax_cross_entropy\n",
    "        val_accuracy = torch.sum(torch.argmax(A2_val, dim=-1) == torch.argmax(y_val, dim=-1)) / y_val.shape[0]\n",
    "\n",
    "    train_losses.append(running_loss/num_batches)\n",
    "    val_losses.append(val_loss.item())\n",
    "    val_accuracies.append(val_accuracy.item())\n",
    "        \n",
    "    # 13. 損失ログ出力\n",
    "    print(f'epoch: {epoch+1}: train loss:{running_loss/num_batches}, val loss: {val_loss.item()}, val accuracy: {val_accuracy.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a17def-3a28-4584-b10a-6ca0d1d608cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x413c95b070>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41555ccc-fe91-42e7-accb-f23ea81fe4c9",
   "metadata": {},
   "source": [
    "### 回帰NNのbackprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "082c4f04-de2a-45ce-b15d-26bd93c38259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "y_train_reg = torch.argmax(y_train, dim=-1)\n",
    "\n",
    "def mse(X, y):\n",
    "    return (X[:, 0] - y).pow(2).mean()\n",
    "\n",
    "def forward_and_backward(X, y):\n",
    "    # forward\n",
    "    Z1 = linear(X, W1, b1)\n",
    "    Z1.retain_grad()\n",
    "    A1 = relu(Z1)\n",
    "    A1.retain_grad()\n",
    "    Z2 = linear(A1, W2, b2)\n",
    "    Z2.retain_grad()\n",
    "    # loss, A2 = softmax_cross_entropy(Z2, y) # -> MSE\n",
    "    loss = mse(Z2, y)\n",
    "\n",
    "    # backward\n",
    "    # Z2.grad_ = (A2 - y) / X.shape[0] # -> MSE\n",
    "    Z2.grad_ = 2 * (Z2 - y.unsqueeze(dim=-1)) / X.shape[0]\n",
    "    linear_backward(A1, W2, b2, Z2)\n",
    "    relu_backward(Z1, A1)\n",
    "    linear_backward(X, W1, b1, Z1)\n",
    "    return loss, Z1, A1, Z2, A2\n",
    "    \n",
    "# パラメータの初期化\n",
    "m, n = X_train.shape\n",
    "nh = 30\n",
    "# パラメータの初期化\n",
    "W1 = torch.randn((nh, n), requires_grad=True) # 出力 x 入力\n",
    "b1 = torch.zeros((1, nh), requires_grad=True) # 1 x nh\n",
    "\n",
    "W2 = torch.randn((1, nh), requires_grad=True) # 出力 x 入力\n",
    "b2 = torch.zeros((1, 1), requires_grad=True) # 1 x 1\n",
    "loss, Z1, A1, Z2, A2 = forward_and_backward(X_train, y_train_reg)\n",
    "loss.backward()\n",
    "\n",
    "# autogradと等しいことを確認\n",
    "print(torch.allclose(W1.grad_, W1.grad))\n",
    "print(torch.allclose(b1.grad_, b1.grad))\n",
    "print(torch.allclose(W2.grad_, W2.grad))\n",
    "print(torch.allclose(b2.grad_, b2.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab78ea9e-81bf-4297-be1f-bf930e2bcdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reg = torch.argmax(y_train, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede6ca4-1d4b-4c87-aa55-26d6926c3704",
   "metadata": {},
   "source": [
    "### Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "020f436a-7b3e-4d97-b3fd-b9c931e0f144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0: train error: 2.4863665948311486, validation error: 5.428891181945801, validation accuracy: 0.1388888955116272\n",
      "epoch: 1: train error: 2.057784676551819, validation error: 4.521430492401123, validation accuracy: 0.21111111342906952\n",
      "epoch: 2: train error: 1.8510736202200253, validation error: 4.149452209472656, validation accuracy: 0.3222222328186035\n",
      "epoch: 3: train error: 1.6693242316444714, validation error: 3.9049906730651855, validation accuracy: 0.3861111104488373\n",
      "epoch: 4: train error: 1.5023181115587552, validation error: 3.70082950592041, validation accuracy: 0.43611112236976624\n",
      "epoch: 5: train error: 1.3438774024446805, validation error: 3.392599105834961, validation accuracy: 0.47777777910232544\n",
      "epoch: 6: train error: 1.2006252047916253, validation error: 3.012922525405884, validation accuracy: 0.5305555462837219\n",
      "epoch: 7: train error: 1.0713975516458352, validation error: 2.5972721576690674, validation accuracy: 0.574999988079071\n",
      "epoch: 8: train error: 0.9594119129081567, validation error: 2.204652786254883, validation accuracy: 0.605555534362793\n",
      "epoch: 9: train error: 0.8661959829429785, validation error: 2.0469446182250977, validation accuracy: 0.6305555701255798\n",
      "epoch: 10: train error: 0.7866797707974911, validation error: 1.8016948699951172, validation accuracy: 0.6583333611488342\n",
      "epoch: 11: train error: 0.7217717518409094, validation error: 1.6245571374893188, validation accuracy: 0.6972222328186035\n",
      "epoch: 12: train error: 0.667019534856081, validation error: 1.5428463220596313, validation accuracy: 0.7166666388511658\n",
      "epoch: 13: train error: 0.6211926136165857, validation error: 1.413733959197998, validation accuracy: 0.7527777552604675\n",
      "epoch: 14: train error: 0.5795518147448698, validation error: 1.2943881750106812, validation accuracy: 0.7666666507720947\n",
      "epoch: 15: train error: 0.5445491739859184, validation error: 1.2582803964614868, validation accuracy: 0.7777777910232544\n",
      "epoch: 16: train error: 0.5125618980576595, validation error: 1.1823970079421997, validation accuracy: 0.7916666865348816\n",
      "epoch: 17: train error: 0.48519804887473583, validation error: 1.110830307006836, validation accuracy: 0.7972221970558167\n",
      "epoch: 18: train error: 0.45957426850994426, validation error: 1.09498929977417, validation accuracy: 0.8055555820465088\n",
      "epoch: 19: train error: 0.4359448716665308, validation error: 1.0585006475448608, validation accuracy: 0.8166666626930237\n",
      "epoch: 20: train error: 0.41581826470792294, validation error: 1.052819013595581, validation accuracy: 0.8138889074325562\n",
      "epoch: 21: train error: 0.3980253227055073, validation error: 1.008387804031372, validation accuracy: 0.8222222328186035\n",
      "epoch: 22: train error: 0.3810272462045153, validation error: 0.9877716302871704, validation accuracy: 0.8333333134651184\n",
      "epoch: 23: train error: 0.36567141364018124, validation error: 0.9588829278945923, validation accuracy: 0.8472222089767456\n",
      "epoch: 24: train error: 0.3519326625391841, validation error: 0.9644975662231445, validation accuracy: 0.8472222089767456\n",
      "epoch: 25: train error: 0.3394089412565033, validation error: 0.9399228692054749, validation accuracy: 0.8527777791023254\n",
      "epoch: 26: train error: 0.3278294447809458, validation error: 0.9514832496643066, validation accuracy: 0.8611111044883728\n",
      "epoch: 27: train error: 0.3169180058563749, validation error: 0.9270197749137878, validation accuracy: 0.8638888597488403\n",
      "epoch: 28: train error: 0.3071232444296281, validation error: 0.9551451802253723, validation accuracy: 0.8666666746139526\n",
      "epoch: 29: train error: 0.2979777216290434, validation error: 0.9259246587753296, validation accuracy: 0.8666666746139526\n",
      "epoch: 30: train error: 0.2888627949481209, validation error: 0.9678598046302795, validation accuracy: 0.8722222447395325\n",
      "epoch: 31: train error: 0.2806473160162568, validation error: 0.9536873698234558, validation accuracy: 0.8722222447395325\n",
      "epoch: 32: train error: 0.2730260584503412, validation error: 0.9652808308601379, validation accuracy: 0.875\n",
      "epoch: 33: train error: 0.26577227454011637, validation error: 0.9460593461990356, validation accuracy: 0.8805555701255798\n",
      "epoch: 34: train error: 0.25858597410842776, validation error: 0.969369649887085, validation accuracy: 0.8861111402511597\n",
      "epoch: 35: train error: 0.25217885834475356, validation error: 0.9672384262084961, validation accuracy: 0.8888888955116272\n",
      "epoch: 36: train error: 0.24654239493732652, validation error: 0.99543297290802, validation accuracy: 0.8861111402511597\n",
      "epoch: 37: train error: 0.24110350959623852, validation error: 0.9936909079551697, validation accuracy: 0.8833333253860474\n",
      "epoch: 38: train error: 0.23583616393928727, validation error: 0.9772593975067139, validation accuracy: 0.8888888955116272\n",
      "epoch: 39: train error: 0.2299345099988083, validation error: 1.0193536281585693, validation accuracy: 0.8722222447395325\n",
      "epoch: 40: train error: 0.225761027696232, validation error: 1.0130687952041626, validation accuracy: 0.8833333253860474\n",
      "epoch: 41: train error: 0.22130635644619664, validation error: 1.0543149709701538, validation accuracy: 0.8805555701255798\n",
      "epoch: 42: train error: 0.21738160448148847, validation error: 1.0424647331237793, validation accuracy: 0.8833333253860474\n",
      "epoch: 43: train error: 0.2129078459305068, validation error: 1.0241698026657104, validation accuracy: 0.8861111402511597\n",
      "epoch: 44: train error: 0.209813195746392, validation error: 1.0699135065078735, validation accuracy: 0.8833333253860474\n",
      "epoch: 45: train error: 0.20540713410203656, validation error: 1.0457913875579834, validation accuracy: 0.8861111402511597\n",
      "epoch: 46: train error: 0.20203148449460664, validation error: 1.0667521953582764, validation accuracy: 0.8861111402511597\n",
      "epoch: 47: train error: 0.19855021623273691, validation error: 1.072441816329956, validation accuracy: 0.8861111402511597\n",
      "epoch: 48: train error: 0.1957005181660255, validation error: 1.0842523574829102, validation accuracy: 0.8861111402511597\n",
      "epoch: 49: train error: 0.1923720434618493, validation error: 1.0673866271972656, validation accuracy: 0.8888888955116272\n",
      "epoch: 50: train error: 0.1891937617522975, validation error: 1.1097619533538818, validation accuracy: 0.8861111402511597\n",
      "epoch: 51: train error: 0.18664626474492252, validation error: 1.115281105041504, validation accuracy: 0.8833333253860474\n",
      "epoch: 52: train error: 0.18343293682361642, validation error: 1.1193690299987793, validation accuracy: 0.8861111402511597\n",
      "epoch: 53: train error: 0.18066271751498184, validation error: 1.1259596347808838, validation accuracy: 0.8833333253860474\n",
      "epoch: 54: train error: 0.1780543792216728, validation error: 1.0907881259918213, validation accuracy: 0.8861111402511597\n",
      "epoch: 55: train error: 0.17600316290433207, validation error: 1.1540472507476807, validation accuracy: 0.8833333253860474\n",
      "epoch: 56: train error: 0.1736607268297424, validation error: 1.1796950101852417, validation accuracy: 0.8777777552604675\n",
      "epoch: 57: train error: 0.1710137565775464, validation error: 1.1717311143875122, validation accuracy: 0.8777777552604675\n",
      "epoch: 58: train error: 0.16897287468115488, validation error: 1.176048994064331, validation accuracy: 0.8777777552604675\n",
      "epoch: 59: train error: 0.16648821067065, validation error: 1.1767313480377197, validation accuracy: 0.8805555701255798\n",
      "epoch: 60: train error: 0.1649241604997466, validation error: 1.184505581855774, validation accuracy: 0.8805555701255798\n",
      "epoch: 61: train error: 0.1627367991798868, validation error: 1.2181445360183716, validation accuracy: 0.8777777552604675\n",
      "epoch: 62: train error: 0.1608222695067525, validation error: 1.2229442596435547, validation accuracy: 0.875\n",
      "epoch: 63: train error: 0.15879622342375418, validation error: 1.205992341041565, validation accuracy: 0.875\n",
      "epoch: 64: train error: 0.1573893215196828, validation error: 1.21963369846344, validation accuracy: 0.875\n",
      "epoch: 65: train error: 0.15503710554912686, validation error: 1.2139190435409546, validation accuracy: 0.8777777552604675\n",
      "epoch: 66: train error: 0.1532497270964086, validation error: 1.2472145557403564, validation accuracy: 0.875\n",
      "epoch: 67: train error: 0.15135439593965808, validation error: 1.2441184520721436, validation accuracy: 0.875\n",
      "epoch: 68: train error: 0.14991844383378825, validation error: 1.2556051015853882, validation accuracy: 0.8777777552604675\n",
      "epoch: 69: train error: 0.14784312760457397, validation error: 1.2206096649169922, validation accuracy: 0.875\n",
      "epoch: 70: train error: 0.14675738872028887, validation error: 1.2740800380706787, validation accuracy: 0.875\n",
      "epoch: 71: train error: 0.14475327800028026, validation error: 1.287008285522461, validation accuracy: 0.8694444298744202\n",
      "epoch: 72: train error: 0.14416959524775544, validation error: 1.2772071361541748, validation accuracy: 0.875\n",
      "epoch: 73: train error: 0.14254122623242438, validation error: 1.2688288688659668, validation accuracy: 0.8722222447395325\n",
      "epoch: 74: train error: 0.14059675058039525, validation error: 1.293318271636963, validation accuracy: 0.8722222447395325\n",
      "epoch: 75: train error: 0.13973272599590322, validation error: 1.3394899368286133, validation accuracy: 0.8638888597488403\n",
      "epoch: 76: train error: 0.13859227198796967, validation error: 1.307742714881897, validation accuracy: 0.8694444298744202\n",
      "epoch: 77: train error: 0.1369098604967197, validation error: 1.2962671518325806, validation accuracy: 0.8694444298744202\n",
      "epoch: 78: train error: 0.1357654632690052, validation error: 1.3017641305923462, validation accuracy: 0.8694444298744202\n",
      "epoch: 79: train error: 0.134177338409548, validation error: 1.3321765661239624, validation accuracy: 0.8666666746139526\n",
      "epoch: 80: train error: 0.13311857365382215, validation error: 1.3299747705459595, validation accuracy: 0.8694444298744202\n",
      "epoch: 81: train error: 0.13147060006546477, validation error: 1.3212705850601196, validation accuracy: 0.8666666746139526\n",
      "epoch: 82: train error: 0.13050647592172027, validation error: 1.3124020099639893, validation accuracy: 0.8694444298744202\n",
      "epoch: 83: train error: 0.12940904148854315, validation error: 1.343632459640503, validation accuracy: 0.8666666746139526\n",
      "epoch: 84: train error: 0.12830609688535333, validation error: 1.3510191440582275, validation accuracy: 0.8694444298744202\n",
      "epoch: 85: train error: 0.12729238093985865, validation error: 1.3597486019134521, validation accuracy: 0.8611111044883728\n",
      "epoch: 86: train error: 0.12621674535330385, validation error: 1.3456647396087646, validation accuracy: 0.8666666746139526\n",
      "epoch: 87: train error: 0.12512632637905577, validation error: 1.3685925006866455, validation accuracy: 0.8694444298744202\n",
      "epoch: 88: train error: 0.12442558833087485, validation error: 1.3850338459014893, validation accuracy: 0.8666666746139526\n",
      "epoch: 89: train error: 0.12309736075500648, validation error: 1.3669353723526, validation accuracy: 0.8666666746139526\n",
      "epoch: 90: train error: 0.12259561258057754, validation error: 1.372043490409851, validation accuracy: 0.8666666746139526\n",
      "epoch: 91: train error: 0.12117857109600057, validation error: 1.3980244398117065, validation accuracy: 0.8666666746139526\n",
      "epoch: 92: train error: 0.12028517201542854, validation error: 1.3872743844985962, validation accuracy: 0.8666666746139526\n",
      "epoch: 93: train error: 0.11921776994131505, validation error: 1.4306637048721313, validation accuracy: 0.8666666746139526\n",
      "epoch: 94: train error: 0.11808974524804701, validation error: 1.407932996749878, validation accuracy: 0.8638888597488403\n",
      "epoch: 95: train error: 0.11690939978385965, validation error: 1.4123457670211792, validation accuracy: 0.8666666746139526\n",
      "epoch: 96: train error: 0.11664005811326206, validation error: 1.4217405319213867, validation accuracy: 0.8666666746139526\n",
      "epoch: 97: train error: 0.11560621888687213, validation error: 1.4283170700073242, validation accuracy: 0.8666666746139526\n",
      "epoch: 98: train error: 0.11462212206485371, validation error: 1.419090747833252, validation accuracy: 0.8666666746139526\n",
      "epoch: 99: train error: 0.11342799116391689, validation error: 1.4390712976455688, validation accuracy: 0.8638888597488403\n"
     ]
    }
   ],
   "source": [
    "# ======モデル======\n",
    "class Linear():\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.W = torch.randn((out_features, in_features)) * torch.sqrt(torch.tensor(2.0 / in_features))\n",
    "        self.W.requires_grad = True\n",
    "        self.b = torch.zeros((1, out_features), requires_grad=True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.Z = X @ self.W.T + self.b\n",
    "        return self.Z\n",
    "\n",
    "    def backward(self, Z):\n",
    "        self.W.grad_ = Z.grad_.T @ self.X\n",
    "        self.b.grad_ = torch.sum(Z.grad_, dim=0)\n",
    "        self.X.grad_ = Z.grad_ @ self.W\n",
    "        return self.X.grad_\n",
    "\n",
    "class ReLU():\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        return X.clamp_min(0.)\n",
    "\n",
    "    def backward(self, A):\n",
    "        return A.grad_ * (self.X > 0).float()\n",
    "\n",
    "class SoftmaxCrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        e_x = torch.exp(X - torch.max(X, dim=-1, keepdim=True)[0])\n",
    "        self.softmax_out = e_x / (torch.sum(e_x, dim=-1, keepdim=True) + 1e-10)    \n",
    "        \n",
    "        log_probs = torch.log(self.softmax_out + 1e-10)\n",
    "        target_log_probs = log_probs * y\n",
    "\n",
    "        self.loss = -target_log_probs.sum(dim=-1).mean()\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, y):\n",
    "        return (self.softmax_out - y) / y.shape[0]\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, input_features, hidden_units, output_units):\n",
    "        self.linear1 = Linear(input_features, hidden_units)\n",
    "        self.relu = ReLU()\n",
    "        self.linear2 = Linear(hidden_units, output_units)\n",
    "        self.loss_fn = SoftmaxCrossEntropy()\n",
    "        \n",
    "    def forward(self, X, y):\n",
    "        self.X = X\n",
    "        self.Z1 = self.linear1.forward(X)\n",
    "        self.A1 = self.relu.forward(self.Z1)\n",
    "        self.Z2 = self.linear2.forward(self.A1)\n",
    "        self.loss = self.loss_fn.forward(self.Z2, y)\n",
    "        return self.loss, self.Z2\n",
    "    \n",
    "    def backward(self, y):\n",
    "        self.Z2.grad_ = self.loss_fn.backward(y)\n",
    "        self.A1.grad_ = self.linear2.backward(self.Z2)\n",
    "        self.Z1.grad_ = self.relu.backward(self.A1)\n",
    "        self.X.grad_ = self.linear1.backward(self.Z1)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        # 勾配の初期化\n",
    "        self.linear1.W.grad_ = None\n",
    "        self.linear1.b.grad_ = None\n",
    "        self.linear2.W.grad_ = None\n",
    "        self.linear2.b.grad_ = None\n",
    "        \n",
    "    def step(self, learning_rate):\n",
    "        # パラメータの更新\n",
    "        self.linear1.W -= learning_rate * self.linear1.W.grad_\n",
    "        self.linear1.b -= learning_rate * self.linear1.b.grad_\n",
    "        self.linear2.W -= learning_rate * self.linear2.W.grad_\n",
    "        self.linear2.b -= learning_rate * self.linear2.b.grad_\n",
    "\n",
    "## Refactoring後の学習ループ(OptimizerやDataset, Dataloaderは後ほどRefactoring)\n",
    "# ===データの準備====\n",
    "dataset = datasets.load_digits()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "images = dataset['images']\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size=0.2, random_state=42)\n",
    "X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "X_val = (X_val - X_train.mean()) / X_train.std()\n",
    "X_train = torch.tensor(X_train.reshape(-1, 64), dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val.reshape(-1, 64), dtype=torch.float32)\n",
    "y_train = F.one_hot(torch.tensor(y_train), num_classes=10) #1437 x 10 \n",
    "y_val = F.one_hot(torch.tensor(y_val), num_classes=10) # 360 x 10\n",
    "batch_size = 30\n",
    "# モデルの初期化\n",
    "model = Model(input_features=64, hidden_units=10, output_units=10)\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# ログ\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "for epoch in range(100):\n",
    "    # エポック毎にデータをシャッフル\n",
    "    shuffled_indices = np.random.permutation(len(y_train))\n",
    "    num_batches = np.ceil(len(y_train)/batch_size).astype(int)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        \n",
    "        # mini batch作成\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        batch_indices = shuffled_indices[start:end]\n",
    "        y_true_ = y_train[batch_indices, :] # batch_size x 10\n",
    "        \n",
    "        X = X_train[batch_indices] # batch_size x 64\n",
    "        # 順伝播と逆伝播の計算\n",
    "        loss, _ = model.forward(X, y_true_)\n",
    "        model.backward(y_true_)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # パラメータ更新\n",
    "        with torch.no_grad():\n",
    "            model.step(learning_rate)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        val_loss, Z2_val = model.forward(X_val, y_val)\n",
    "        \n",
    "        val_accuracy = torch.sum(torch.argmax(Z2_val, dim=-1) == torch.argmax(y_val, dim=-1)) / y_val.shape[0]\n",
    "\n",
    "    train_losses.append(running_loss/num_batches)\n",
    "    val_losses.append(val_loss.item())\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f'epoch: {epoch}: train error: {running_loss/num_batches}, validation error: {val_loss.item()}, validation accuracy: {val_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
