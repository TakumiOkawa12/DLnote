{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e764c6-2b88-4963-a245-98d125c8a2a2",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a8190-40a0-42f5-a77a-900f0a688018",
   "metadata": {},
   "source": [
    "## Backwardをスクラッチで実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d033fb8b-166a-41ec-9f01-454ea43a2e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ca4c884e-a846-466d-9364-48349930f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(A, W, b, Z):\n",
    "    W.grad_ = Z.grad_.T @ A\n",
    "    b.grad_ = torch.sum(Z.grad_, dim = 0)\n",
    "    A.grad_ = Z.grad_ @ W\n",
    "\n",
    "def relu_backward(Z, A):\n",
    "    Z.grad_ = A.grad_ * (Z > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67235437-9e22-40f7-84d2-c20ac3ee2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy(x, y_true):\n",
    "    e_x = torch.exp(x - torch.max(x, dim = 1, keepdim = True)[0])\n",
    "    softmax_out = e_x / (torch.sum(e_x, dim = 1, keepdim = True) + 1e-10)\n",
    "    loss = - torch.sum(y_true * torch.log(softmax_out + 1e-10)) / softmax_out.shape[0]\n",
    "    return loss, softmax_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81fb663b-383e-41bd-9d1b-8291569ed852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return Z.clamp_min(0.)\n",
    "\n",
    "def linear(X, W, b):\n",
    "    return X @ W.T + b\n",
    "\n",
    "def forward_and_backward(X, y):\n",
    "    # forward\n",
    "    Z1 = linear(X, W1, b1)\n",
    "    # Z1.retain_grad()\n",
    "    A1 = relu(Z1)\n",
    "    # A1.retain_grad()\n",
    "    Z2 = linear(A1, W2, b2)\n",
    "    # Z2.retain_grad()\n",
    "    loss, A2 = softmax_cross_entropy(Z2, y)\n",
    "\n",
    "    # backward\n",
    "    Z2.grad_ = (A2 - y) / X.shape[0]\n",
    "    linear_backward(A1, W2, b2, Z2)\n",
    "    relu_backward(Z1, A1)\n",
    "    linear_backward(X, W1, b1, Z1)\n",
    "    return loss, Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363945ed-29c7-4c8d-8162-bb8ca2433e91",
   "metadata": {},
   "source": [
    "## Autogradの結果と一致することを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c4c8bd17-46a9-40b7-8a21-1a4cdbe1a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. データロード\n",
    "dataset = datasets.load_digits()\n",
    "images = dataset['images']\n",
    "target = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1a959f06-8f34-4204-96d8-3345a78d0ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 8, 8) (1437,)\n",
      "(360, 8, 8) (360,)\n"
     ]
    }
   ],
   "source": [
    "# 学習データと検証データ分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "866dfb30-9086-4a35-9ee6-06076f2a95bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "# 2-1.ラベルのone-hot encoing\n",
    "y_train = F.one_hot(torch.tensor(y_train), num_classes=10)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).reshape(-1, 64)\n",
    "\n",
    "y_val = F.one_hot(torch.tensor(y_val), num_classes=10)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).reshape(-1, 64)\n",
    "\n",
    "# 2-2. 画像の標準化\n",
    "X_train_mean = X_train.mean()\n",
    "X_train_std = X_train.std()\n",
    "X_train = (X_train - X_train_mean) / X_train_std\n",
    "X_val = (X_val - X_train_mean) / X_train_std\n",
    "# 以下のように手元のデータ全ての平均&標準偏差を使えば，学習データと検証データの分布を近くすることが可能\n",
    "# しかし，この場合validationの精度は，未知のデータよりも若干高くなることに注意\n",
    "# X_train = (X_train - images.mean()) / images.std()\n",
    "# X_val = (X_val - images.mean()) / images.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b244ff-b16c-4f77-aa36-d7cf1dd8dd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの初期化\n",
    "nh = 30\n",
    "m, n = X_train.shape\n",
    "class_num = 10\n",
    "W1 = torch.randn((nh, n), requires_grad = True)\n",
    "b1 = torch.zeros((1, nh), requires_grad = True)\n",
    "W2 = torch.randn((class_num, nh), requires_grad = True)\n",
    "b2 = torch.zeros((1, class_num), requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d0e8b3a-9980-45d2-8f78-07eead07bc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2 : tensor([[ 1.3143e-02,  1.1095e-01,  4.5824e-02,  3.9017e-02,  2.1677e-01,\n",
      "          2.1051e-01,  2.0029e-01,  5.5688e-03,  4.1368e-02,  4.0444e-02,\n",
      "          1.1161e-01,  2.5959e-01, -6.2764e-03,  1.0683e-02,  2.9299e-02,\n",
      "          9.1153e-02,  1.1856e-02,  7.5364e-02,  1.1260e-02,  1.2083e-01,\n",
      "          4.1484e-03,  5.7614e-01, -2.6559e-03,  3.7110e-02,  8.8376e-02,\n",
      "          1.3256e-01,  2.3965e-02, -2.9610e-02,  1.6344e-01,  1.0113e-01],\n",
      "        [-3.5813e-02, -6.6053e-02, -2.0150e-03, -1.7855e-02, -1.9278e-01,\n",
      "         -2.5582e-02, -1.7957e-02, -4.8477e-03, -2.2143e-04, -3.9434e-02,\n",
      "         -3.4049e-02, -2.4977e-01,  1.2974e-05,  2.9152e-04, -4.8854e-03,\n",
      "         -1.0347e-01, -6.3627e-03, -4.5157e-02, -1.2366e-02, -1.0970e-01,\n",
      "          2.0201e-05, -2.3648e-01, -7.2061e-05, -1.8631e-02, -3.3196e-02,\n",
      "         -6.8120e-02, -3.9963e-03, -4.8885e-03, -4.0558e-02, -2.2681e-02],\n",
      "        [ 1.6471e-01, -4.5845e-02, -8.2367e-02, -8.9978e-02,  1.2123e-01,\n",
      "          2.4588e-03,  3.8668e-02, -4.4285e-04, -1.9361e-01, -1.7777e-02,\n",
      "          9.5847e-03,  7.2513e-02, -2.0567e-02, -3.0922e-02,  1.0898e-02,\n",
      "          4.5649e-02,  1.3196e-02, -3.7125e-01, -4.3449e-04,  4.4234e-03,\n",
      "          9.1227e-03, -3.3271e-01,  7.8402e-02, -3.3639e-04, -8.7494e-02,\n",
      "          1.7263e-02, -9.6507e-02, -2.2800e-02, -1.1384e-01,  3.5553e-02],\n",
      "        [ 6.4207e-02,  2.9704e-03, -5.1830e-03, -6.5069e-03,  4.7400e-03,\n",
      "          6.6800e-03,  2.0186e-02,  4.7125e-05, -8.1598e-03,  7.5248e-02,\n",
      "          6.7096e-02, -2.0087e-02,  1.1727e-02,  7.4827e-03,  1.0652e-05,\n",
      "          2.7823e-02,  1.7877e-02,  1.8677e-02,  5.7436e-04,  1.5930e-02,\n",
      "         -5.3737e-04,  2.6889e-02,  4.7467e-02,  7.7954e-03,  4.5414e-02,\n",
      "         -3.0753e-03,  1.0226e-02,  2.6411e-02,  8.2854e-02,  2.8658e-03],\n",
      "        [-3.8062e-02, -2.9556e-02,  4.5193e-03,  1.8619e-02, -7.8481e-02,\n",
      "         -4.6380e-02, -3.6654e-02,  8.8770e-14,  1.2204e-03, -3.2180e-02,\n",
      "         -3.9797e-04, -1.6506e-01, -2.9376e-03,  3.6704e-03, -3.7776e-02,\n",
      "         -3.6542e-02, -4.6729e-02,  3.4787e-04,  3.1391e-04,  2.0211e-02,\n",
      "          9.1084e-03, -1.1893e-01, -1.6555e-02, -5.1146e-02,  1.2929e-02,\n",
      "         -2.2870e-02,  1.3674e-06, -6.0910e-02, -9.9389e-02,  2.2662e-03],\n",
      "        [-2.0132e-02, -1.3090e-02, -1.6909e-02,  1.4585e-02,  6.0047e-02,\n",
      "         -1.5742e-01, -1.3674e-01,  8.8656e-05, -3.1681e-02,  9.4439e-03,\n",
      "         -2.1066e-02,  1.0193e-01, -4.6348e-03,  1.4015e-03, -2.2649e-03,\n",
      "         -4.1967e-03,  1.2241e-02,  2.4916e-03,  7.2726e-04,  4.5465e-03,\n",
      "         -8.3150e-03,  1.5807e-02, -1.2035e-01,  7.3785e-03, -6.4410e-02,\n",
      "          8.0382e-03, -2.8060e-03,  9.0049e-03,  4.2998e-02, -3.6589e-01],\n",
      "        [-2.4928e-01,  5.6910e-03,  2.6162e-02,  5.9383e-05, -8.0390e-02,\n",
      "          1.4898e-01,  1.5520e-01,  2.7961e-10,  5.6006e-02, -2.0280e-01,\n",
      "         -2.0043e-01,  5.4705e-02, -7.2152e-03, -8.5729e-03,  2.4979e-02,\n",
      "         -3.6910e-03, -4.2687e-02,  7.4648e-03,  3.5658e-04, -7.0083e-02,\n",
      "          4.1454e-03,  2.8929e-01, -1.2328e-01,  7.6161e-02, -7.5484e-02,\n",
      "          4.0566e-02,  1.7757e-02,  5.5880e-02, -2.3126e-01,  1.9615e-01],\n",
      "        [ 1.6481e-01,  3.9186e-03,  5.0068e-03,  4.9348e-03,  6.2550e-02,\n",
      "          9.2760e-03,  2.3455e-02, -7.3503e-12,  2.3208e-04,  1.7235e-01,\n",
      "          7.0567e-02,  2.6896e-03,  2.6258e-03,  7.3545e-03,  1.0394e-02,\n",
      "          2.1090e-02,  3.9244e-02,  3.5354e-03,  2.5888e-04,  8.3026e-02,\n",
      "          1.6935e-11,  1.6650e-02,  5.8896e-02,  1.1685e-03,  8.6153e-02,\n",
      "          5.0217e-03,  1.3745e-04,  1.9151e-03,  1.3278e-01,  5.5584e-02],\n",
      "        [-2.4240e-02, -5.0109e-02,  2.3596e-02, -2.5000e-02, -7.4612e-02,\n",
      "         -6.1746e-02, -1.8174e-02, -1.2034e-03,  1.6637e-02, -1.3865e-01,\n",
      "         -1.4205e-01, -4.5362e-02,  4.6136e-03, -1.8429e-02,  9.6368e-03,\n",
      "         -2.3143e-02, -8.0004e-03,  5.8569e-03, -7.4416e-03, -1.5684e-01,\n",
      "          1.6338e-02, -2.0388e-01,  4.8769e-03, -4.9853e-02, -5.6454e-02,\n",
      "         -6.1819e-02, -1.0891e-02,  3.6682e-02, -1.2528e-01,  1.1485e-01],\n",
      "        [-3.9341e-02,  8.1119e-02,  1.3651e-03,  6.2123e-02, -3.9075e-02,\n",
      "         -8.6774e-02, -2.2828e-01,  7.8927e-04,  1.1821e-01,  1.3336e-01,\n",
      "          1.3914e-01, -1.1151e-02,  2.2651e-02,  2.7040e-02, -4.0292e-02,\n",
      "         -1.4675e-02,  9.3654e-03,  3.0266e-01,  6.7519e-03,  8.7659e-02,\n",
      "         -3.4031e-02, -3.2777e-02,  7.3270e-02, -9.6471e-03,  8.4168e-02,\n",
      "         -4.7569e-02,  6.2113e-02, -1.1685e-02,  1.8825e-01, -1.1982e-01]])\n",
      "b2 : tensor([[ 0.0389, -0.0215, -0.0011,  0.0073, -0.0154, -0.0112,  0.0073,  0.0116,\n",
      "         -0.0146, -0.0013]])\n",
      "W1 : tensor([[ 0.0148,  0.0153,  0.0584,  ..., -0.0241, -0.0097,  0.0158],\n",
      "        [-0.0654, -0.0608,  0.0410,  ...,  0.0516,  0.0088, -0.0441],\n",
      "        [ 0.0155,  0.0150, -0.0084,  ..., -0.0224, -0.0059,  0.0070],\n",
      "        ...,\n",
      "        [ 0.0069,  0.0064, -0.0039,  ...,  0.0172,  0.0236,  0.0112],\n",
      "        [-0.0270, -0.0251,  0.0094,  ...,  0.0325, -0.0030, -0.0225],\n",
      "        [ 0.0352,  0.0351,  0.0157,  ..., -0.0816, -0.0012,  0.0373]])\n",
      "b1 : tensor([[-1.8225e-02,  8.0612e-02, -1.9099e-02, -5.8132e-03, -1.2091e-02,\n",
      "         -1.3150e-02, -8.1320e-05, -3.0674e-03,  4.2729e-02,  1.9841e-02,\n",
      "          2.5999e-02,  4.9787e-03,  7.9082e-03,  9.0050e-03, -1.4711e-03,\n",
      "          1.4867e-02, -6.3488e-02,  1.9230e-02, -1.5652e-02, -2.1831e-02,\n",
      "          8.2856e-03,  5.5313e-02,  5.6305e-02,  6.0956e-02,  5.3936e-02,\n",
      "          7.7105e-02, -7.4186e-04, -8.5457e-03,  3.3295e-02, -4.3349e-02]])\n"
     ]
    }
   ],
   "source": [
    "# forward\n",
    "Z1 = linear(X_train, W1, b1)\n",
    "A1 = relu(Z1)\n",
    "Z2 = linear(A1, W2, b2)\n",
    "loss, softmax_out = softmax_cross_entropy(Z2, y_train)\n",
    "\n",
    "# backward\n",
    "loss.backward()\n",
    "print(f'W2 : {W2.grad}')\n",
    "print(f'b2 : {b2.grad}')\n",
    "print(f'W1 : {W1.grad}')\n",
    "print(f'b1 : {b1.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5a435fd-0c09-4711-82da-5693ff9c6670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1437, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73bb1d9b-874e-4840-b16b-a8c588497c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, Z1, A1, Z2, A2 = forward_and_backward(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9c6cfa5-1fec-4430-98ef-1458de14cecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0848, -0.0728,  0.1156,  ...,  0.1083, -0.0896, -0.0819],\n",
       "        [-0.4386, -0.3695,  0.3464,  ...,  0.1165, -0.1986, -0.3621],\n",
       "        [-0.0332, -0.0314, -0.0121,  ..., -0.0674, -0.0785, -0.0508],\n",
       "        ...,\n",
       "        [-0.0105, -0.0141, -0.0160,  ..., -0.0101,  0.0223, -0.0028],\n",
       "        [-0.0465, -0.0466, -0.0036,  ...,  0.0797,  0.0044, -0.0391],\n",
       "        [-0.2458, -0.2194,  0.1161,  ...,  0.0891, -0.2243, -0.2342]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.grad_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bb4bc0a-dec2-4754-9aa3-060dd1d5d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograd\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9648aac6-0b5e-4c9d-bdef-c8b4fed0d109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0740,  0.0765,  0.2919,  ..., -0.1206, -0.0484,  0.0788],\n",
       "        [-0.3272, -0.3039,  0.2049,  ...,  0.2580,  0.0439, -0.2203],\n",
       "        [ 0.0775,  0.0749, -0.0421,  ..., -0.1119, -0.0296,  0.0351],\n",
       "        ...,\n",
       "        [ 0.0347,  0.0322, -0.0196,  ...,  0.0858,  0.1178,  0.0559],\n",
       "        [-0.1352, -0.1253,  0.0472,  ...,  0.1626, -0.0150, -0.1125],\n",
       "        [ 0.1760,  0.1756,  0.0784,  ..., -0.4079, -0.0059,  0.1867]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fe84dfd-1ea0-44fb-afe7-07d7149c054a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8300e-35,  7.0304e-09,  2.3612e-05,  ...,  6.6583e-04,\n",
       "          2.6101e-20,  4.0653e-18],\n",
       "        [-6.9589e-04,  1.8616e-21,  1.6223e-20,  ...,  1.1983e-34,\n",
       "          6.9589e-04,  2.8809e-18],\n",
       "        [-6.9589e-04,  3.0313e-15,  3.1849e-10,  ...,  1.6491e-25,\n",
       "          2.4628e-07,  2.9364e-10],\n",
       "        ...,\n",
       "        [ 6.9555e-04,  2.9199e-21, -6.9589e-04,  ...,  2.9016e-34,\n",
       "          9.3428e-28,  3.4734e-07],\n",
       "        [ 6.9573e-04,  6.2657e-17,  1.6456e-07,  ..., -6.9589e-04,\n",
       "          2.5545e-31,  6.9249e-17],\n",
       "        [ 8.0490e-16, -6.9589e-04,  2.1820e-17,  ...,  2.7690e-18,\n",
       "          1.4147e-28,  1.3104e-08]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z2.grad_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92e39b16-003f-466a-953c-e8a51980a1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8300e-35,  7.0304e-09,  2.3612e-05,  ...,  6.6583e-04,\n",
       "          2.6101e-20,  4.0653e-18],\n",
       "        [-9.2388e-11,  2.4715e-28,  2.1537e-27,  ...,  1.5909e-41,\n",
       "          9.2388e-11,  3.8247e-25],\n",
       "        [-1.1026e-05,  4.8031e-17,  5.0465e-12,  ...,  2.6129e-27,\n",
       "          3.9023e-09,  4.6528e-12],\n",
       "        ...,\n",
       "        [ 6.5451e-04,  2.7477e-21, -6.5484e-04,  ...,  2.7304e-34,\n",
       "          8.7915e-28,  3.2685e-07],\n",
       "        [ 4.5367e-28,  4.0858e-41,  1.0731e-31,  ..., -4.5377e-28,\n",
       "          0.0000e+00,  4.5155e-41],\n",
       "        [ 2.4452e-25, -2.1141e-13,  6.6286e-27,  ...,  8.4121e-28,\n",
       "          4.2977e-38,  3.9810e-18]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a2fc4a7-02ab-46ab-907b-326ede496bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradが等しくならない原因としてはsoftmaxでe_xを計算する際に値が大きくなり、不安定になっているため."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8b2047b-0df9-40d6-966e-9c09710638be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの初期化\n",
    "nh = 30\n",
    "m, n = X_train.shape\n",
    "class_num = 10\n",
    "# W1 = torch.randn((nh, n), requires_grad = True)\n",
    "W1 = torch.randn((nh, n)) * torch.sqrt(torch.tensor(2./n))\n",
    "W1.requires_grad = True\n",
    "b1 = torch.zeros((1, nh), requires_grad = True)\n",
    "# W2 = torch.randn((class_num, nh), requires_grad = True)\n",
    "W2 = torch.randn((class_num, nh)) * torch.sqrt(torch.tensor(2./n))\n",
    "W2.requires_grad = True\n",
    "b2 = torch.zeros((1, class_num), requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2563ab6d-873c-491f-a7eb-80cdf95b65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, Z1, A1, Z2, A2 = forward_and_backward(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e054af4c-a83c-424a-8cfe-083ad9f26a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0275, -0.0228,  0.0208,  ...,  0.0504,  0.0230, -0.0163],\n",
       "        [ 0.0078,  0.0076,  0.0036,  ..., -0.0198, -0.0032,  0.0056],\n",
       "        [ 0.0133,  0.0103, -0.0192,  ..., -0.0314, -0.0053,  0.0093],\n",
       "        ...,\n",
       "        [-0.0273, -0.0265,  0.0059,  ...,  0.0566, -0.0071, -0.0264],\n",
       "        [-0.0258, -0.0246, -0.0023,  ...,  0.0062, -0.0152, -0.0200],\n",
       "        [-0.0123, -0.0148, -0.0132,  ...,  0.0103, -0.0171, -0.0136]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.grad_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84cc921a-22c4-4f42-82cb-a852893887b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "349384c7-862a-4ba4-95b8-c15ce59be580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0275, -0.0228,  0.0208,  ...,  0.0504,  0.0230, -0.0163],\n",
       "        [ 0.0078,  0.0076,  0.0036,  ..., -0.0198, -0.0032,  0.0056],\n",
       "        [ 0.0133,  0.0103, -0.0192,  ..., -0.0314, -0.0053,  0.0093],\n",
       "        ...,\n",
       "        [-0.0273, -0.0265,  0.0059,  ...,  0.0566, -0.0071, -0.0264],\n",
       "        [-0.0258, -0.0246, -0.0023,  ...,  0.0062, -0.0152, -0.0200],\n",
       "        [-0.0123, -0.0148, -0.0132,  ...,  0.0103, -0.0171, -0.0136]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82c94c79-7bb1-463f-ba4d-ff132e52f1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(W1.grad_, W1.grad) # 2つの引数が大体同じかを判定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7515c63-61ef-4fc5-a4c5-02db750be261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(W1.grad_, W1.grad))\n",
    "print(torch.allclose(b1.grad_, b1.grad))\n",
    "print(torch.allclose(W2.grad_, W2.grad))\n",
    "print(torch.allclose(b2.grad_, b2.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7dca67-7d99-4c02-b944-1ea9c4eabf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a1f0d16-d2a6-45c3-86fd-a89294a29e0c",
   "metadata": {},
   "source": [
    "## MLPの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b156716-5b79-4ec3-9213-ff9c646eaad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1: train loss:2.0096512536207833, val loss: 1.5038447380065918, val accuracy: 0.5805555582046509\n",
      "epoch: 2: train loss:1.1687088559071224, val loss: 0.881437361240387, val accuracy: 0.8361111283302307\n",
      "epoch: 3: train loss:0.7296830068031946, val loss: 0.5885488986968994, val accuracy: 0.8805555701255798\n",
      "epoch: 4: train loss:0.5257562976330519, val loss: 0.4477424621582031, val accuracy: 0.9027777910232544\n",
      "epoch: 5: train loss:0.4187257358183463, val loss: 0.3690154552459717, val accuracy: 0.9138888716697693\n",
      "epoch: 6: train loss:0.3477826987703641, val loss: 0.31704360246658325, val accuracy: 0.9277777671813965\n",
      "epoch: 7: train loss:0.30237783926228684, val loss: 0.2785642743110657, val accuracy: 0.9305555820465088\n",
      "epoch: 8: train loss:0.2698157539901634, val loss: 0.2557268440723419, val accuracy: 0.9194444417953491\n",
      "epoch: 9: train loss:0.24326804280281067, val loss: 0.2320416271686554, val accuracy: 0.9444444179534912\n",
      "epoch: 10: train loss:0.22276823269203305, val loss: 0.21329529583454132, val accuracy: 0.9444444179534912\n",
      "epoch: 11: train loss:0.20563660825913152, val loss: 0.20162950456142426, val accuracy: 0.9416666626930237\n",
      "epoch: 12: train loss:0.19249197538010776, val loss: 0.18924997746944427, val accuracy: 0.9472222328186035\n",
      "epoch: 13: train loss:0.18085934516663352, val loss: 0.18119661509990692, val accuracy: 0.9472222328186035\n",
      "epoch: 14: train loss:0.1701092479440073, val loss: 0.17246274650096893, val accuracy: 0.949999988079071\n",
      "epoch: 15: train loss:0.16013234201818705, val loss: 0.16877903044223785, val accuracy: 0.9472222328186035\n",
      "epoch: 16: train loss:0.1533051785081625, val loss: 0.16046208143234253, val accuracy: 0.9555555582046509\n",
      "epoch: 17: train loss:0.1450298426207155, val loss: 0.15374809503555298, val accuracy: 0.9583333134651184\n",
      "epoch: 18: train loss:0.13834846951067448, val loss: 0.1493338793516159, val accuracy: 0.9583333134651184\n",
      "epoch: 19: train loss:0.13327095688631138, val loss: 0.14375068247318268, val accuracy: 0.9555555582046509\n",
      "epoch: 20: train loss:0.1280373570819696, val loss: 0.13964679837226868, val accuracy: 0.9666666388511658\n",
      "epoch: 21: train loss:0.12290734976219635, val loss: 0.1380549818277359, val accuracy: 0.9611111283302307\n",
      "epoch: 22: train loss:0.11867926844085257, val loss: 0.13352635502815247, val accuracy: 0.9638888835906982\n",
      "epoch: 23: train loss:0.11382992196983348, val loss: 0.13018332421779633, val accuracy: 0.9666666388511658\n",
      "epoch: 24: train loss:0.10976174161381398, val loss: 0.12787391245365143, val accuracy: 0.9666666388511658\n",
      "epoch: 25: train loss:0.10615719831548631, val loss: 0.12588635087013245, val accuracy: 0.9666666388511658\n",
      "epoch: 26: train loss:0.10295577921594183, val loss: 0.12447254359722137, val accuracy: 0.9694444537162781\n",
      "epoch: 27: train loss:0.09958385835246493, val loss: 0.12286991626024246, val accuracy: 0.9638888835906982\n",
      "epoch: 28: train loss:0.09608284609081845, val loss: 0.11985480785369873, val accuracy: 0.9694444537162781\n",
      "epoch: 29: train loss:0.0938425720281278, val loss: 0.11706610769033432, val accuracy: 0.9694444537162781\n",
      "epoch: 30: train loss:0.08920288427422444, val loss: 0.1216219812631607, val accuracy: 0.9694444537162781\n"
     ]
    }
   ],
   "source": [
    "loss_log = []\n",
    "batch_size = 30\n",
    "num_batches = np.ceil(len(y_train) / batch_size).astype(int)\n",
    "learning_rate = 0.03\n",
    "# ログ\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# 3. パラメータの初期化\n",
    "W1 = torch.randn((nh, n)) * torch.sqrt(torch.tensor(2./n))\n",
    "W1.requires_grad = True\n",
    "b1 = torch.zeros((1, nh), requires_grad = True)\n",
    "W2 = torch.randn((class_num, nh)) * torch.sqrt(torch.tensor(2./n))\n",
    "W2.requires_grad = True\n",
    "b2 = torch.zeros((1, class_num), requires_grad = True)\n",
    "\n",
    "# 5. for文で学習ループ作成\n",
    "for epoch in range(30):\n",
    "    shuffled_indices = np.random.permutation(len(y_train))\n",
    "    running_loss = 0\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        # mini batch作成\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_indices = shuffled_indices[start:end]\n",
    "        # 6. 入力データXおよび教師ラベルのYを作成\n",
    "        y_train_ = y_train[batch_indices, :] # データ数xクラス数\n",
    "        X_train_ = X_train[batch_indices, :] # データ数 x 特徴量数\n",
    "        # ブレークポイントを設置\n",
    "        # import pdb; pdb.set_trace()\n",
    "\n",
    "        # 7. Z計算\n",
    "        # Z = X@W.T + b -> MLP\n",
    "        loss, Z1, A1, Z2, A2 = forward_and_backward(X_train_, y_train_)\n",
    "\n",
    "        # 8. softmaxで予測計算\n",
    "        # y_pred = softmax(Z)\n",
    "        \n",
    "\n",
    "        # 9. 損失計算\n",
    "        # loss = cross_entropy(y_true_, y_pred)\n",
    "        loss, softmax_out = softmax_cross_entropy(Z2, y_train_)\n",
    "        loss_log.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 10. 勾配計算\n",
    "        # loss.backward()\n",
    "        \n",
    "\n",
    "        # 11. パラメータ更新\n",
    "        with torch.no_grad():\n",
    "            # W -= learning_rate * W.grad\n",
    "            W1 -= learning_rate * W1.grad_\n",
    "            W2 -= learning_rate * W2.grad_\n",
    "            # b -= learning_rate * b.grad\n",
    "            b1 -= learning_rate * b1.grad_\n",
    "            b2 -= learning_rate * b2.grad_\n",
    "\n",
    "        # 12. 勾配初期化\n",
    "        # W.grad.zero_()\n",
    "        W1.grad_ = None\n",
    "        W2.grad_ = None\n",
    "        # b.grad.zero_()\n",
    "        b1.grad_ = None\n",
    "        b2.grad_ = None\n",
    "\n",
    "    # 13. 損失ログ出力\n",
    "    # print(f'epoch: {epoch+1}: {running_loss/num_batches}')\n",
    "\n",
    "     # validation\n",
    "    with torch.no_grad():\n",
    "        # Z_val = X_val@W.T + b\n",
    "        # y_pred_val = softmax(Z_val)\n",
    "        val_loss, Z1, A1, Z2, A2 = forward_and_backward(X_val, y_val)\n",
    "        val_loss, softmax_out = softmax_cross_entropy(Z2, y_val)\n",
    "        # val_loss = cross_entropy(y_val, y_pred_val)\n",
    "        \n",
    "        val_accuracy = torch.sum(torch.argmax(softmax_out, dim=-1) == torch.argmax(y_val, dim=-1)) / y_val.shape[0]\n",
    "\n",
    "    train_losses.append(running_loss/num_batches)\n",
    "    val_losses.append(val_loss.item())\n",
    "    val_accuracies.append(val_accuracy.item())\n",
    "        \n",
    "    # 13. 損失ログ出力\n",
    "    print(f'epoch: {epoch+1}: train loss:{running_loss/num_batches}, val loss: {val_loss.item()}, val accuracy: {val_accuracy.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d71897f1-cfc5-4eb6-ae5e-b68a95442559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffefeabe700>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97141b69-fedc-4bb3-8af7-d27ed0a878fc",
   "metadata": {},
   "source": [
    "## 回帰NNのbackpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "29ac1936-ca17-4b98-8d60-bc426158f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "y_train_reg = torch.argmax(y_train, dim=-1)\n",
    "\n",
    "def mse(X, y):\n",
    "    return (X[:, 0] - y).pow(2).mean()\n",
    "\n",
    "def forward_and_backward(X, y):\n",
    "    # forward\n",
    "    Z1 = linear(X, W1, b1)\n",
    "    Z1.retain_grad()\n",
    "    A1 = relu(Z1)\n",
    "    A1.retain_grad()\n",
    "    Z2 = linear(A1, W2, b2)\n",
    "    Z2.retain_grad()\n",
    "    # loss, A2 = softmax_cross_entropy(Z2, y) # -> MSE\n",
    "    loss = mse(Z2, y)\n",
    "\n",
    "    # backward\n",
    "    # Z2.grad_ = (A2 - y) / X.shape[0] # -> MSE\n",
    "    Z2.grad_ = 2 * (Z2 - y.unsqueeze(dim=-1)) / X.shape[0]\n",
    "    linear_backward(A1, W2, b2, Z2)\n",
    "    relu_backward(Z1, A1)\n",
    "    linear_backward(X, W1, b1, Z1)\n",
    "    return loss, Z1, A1, Z2, A2\n",
    "    \n",
    "# パラメータの初期化\n",
    "m, n = X_train.shape\n",
    "nh = 30\n",
    "# パラメータの初期化\n",
    "W1 = torch.randn((nh, n), requires_grad=True) # 出力 x 入力\n",
    "b1 = torch.zeros((1, nh), requires_grad=True) # 1 x nh\n",
    "\n",
    "W2 = torch.randn((1, nh), requires_grad=True) # 出力 x 入力\n",
    "b2 = torch.zeros((1, 1), requires_grad=True) # 1 x 1\n",
    "loss, Z1, A1, Z2, A2 = forward_and_backward(X_train, y_train_reg)\n",
    "loss.backward()\n",
    "\n",
    "# autogradと等しいことを確認\n",
    "print(torch.allclose(W1.grad_, W1.grad))\n",
    "print(torch.allclose(b1.grad_, b1.grad))\n",
    "print(torch.allclose(W2.grad_, W2.grad))\n",
    "print(torch.allclose(b2.grad_, b2.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea24d46e-7524-4bdb-bb06-ab2f52008992",
   "metadata": {},
   "source": [
    "## Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1b7e1b29-e763-4f28-b43c-ae6aadc2f354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0: train error: 2.2523440470298133, validation error: 5.471328258514404, validation accuracy: 0.19722221791744232\n",
      "epoch: 1: train error: 1.9940015872319539, validation error: 4.700458526611328, validation accuracy: 0.2638888955116272\n",
      "epoch: 2: train error: 1.8018871371944745, validation error: 4.19155216217041, validation accuracy: 0.3222222328186035\n",
      "epoch: 3: train error: 1.6201553990443547, validation error: 3.888812303543091, validation accuracy: 0.38055557012557983\n",
      "epoch: 4: train error: 1.4540905207395554, validation error: 3.594496250152588, validation accuracy: 0.42500001192092896\n",
      "epoch: 5: train error: 1.2993688136339188, validation error: 3.2498958110809326, validation accuracy: 0.4833333194255829\n",
      "epoch: 6: train error: 1.1563137955963612, validation error: 3.0558485984802246, validation accuracy: 0.5138888955116272\n",
      "epoch: 7: train error: 1.0330120126406352, validation error: 2.7142179012298584, validation accuracy: 0.5583333373069763\n",
      "epoch: 8: train error: 0.9300419315695763, validation error: 2.614687204360962, validation accuracy: 0.5777778029441833\n",
      "epoch: 9: train error: 0.8464253631730875, validation error: 2.3397583961486816, validation accuracy: 0.6138888597488403\n",
      "epoch: 10: train error: 0.7777165820201238, validation error: 2.240875244140625, validation accuracy: 0.6361111402511597\n",
      "epoch: 11: train error: 0.7183137269069751, validation error: 2.277409553527832, validation accuracy: 0.6388888955116272\n",
      "epoch: 12: train error: 0.6681647431105375, validation error: 2.1094400882720947, validation accuracy: 0.6666666865348816\n",
      "epoch: 13: train error: 0.62314941175282, validation error: 2.0087177753448486, validation accuracy: 0.6805555820465088\n",
      "epoch: 14: train error: 0.5838581354667743, validation error: 1.870063066482544, validation accuracy: 0.6944444179534912\n",
      "epoch: 15: train error: 0.5476941242814064, validation error: 1.6551774740219116, validation accuracy: 0.7111111283302307\n",
      "epoch: 16: train error: 0.5159199138482412, validation error: 1.696711778640747, validation accuracy: 0.730555534362793\n",
      "epoch: 17: train error: 0.48738250384728116, validation error: 1.743484377861023, validation accuracy: 0.7277777791023254\n",
      "epoch: 18: train error: 0.4622041055311759, validation error: 1.6074481010437012, validation accuracy: 0.7416666746139526\n",
      "epoch: 19: train error: 0.4385065380483866, validation error: 1.5277533531188965, validation accuracy: 0.7472222447395325\n",
      "epoch: 20: train error: 0.41684258294602233, validation error: 1.5357710123062134, validation accuracy: 0.7555555701255798\n",
      "epoch: 21: train error: 0.3982990253716707, validation error: 1.4527812004089355, validation accuracy: 0.769444465637207\n",
      "epoch: 22: train error: 0.38114453728000325, validation error: 1.446823239326477, validation accuracy: 0.7749999761581421\n",
      "epoch: 23: train error: 0.365556750446558, validation error: 1.335538625717163, validation accuracy: 0.7972221970558167\n",
      "epoch: 24: train error: 0.3510851766914129, validation error: 1.3161128759384155, validation accuracy: 0.7944444417953491\n",
      "epoch: 25: train error: 0.33854109173019725, validation error: 1.1856573820114136, validation accuracy: 0.8194444179534912\n",
      "epoch: 26: train error: 0.3268382027745247, validation error: 1.228005290031433, validation accuracy: 0.8194444179534912\n",
      "epoch: 27: train error: 0.3155283114562432, validation error: 1.2928800582885742, validation accuracy: 0.8111110925674438\n",
      "epoch: 28: train error: 0.30605310543129843, validation error: 1.143170714378357, validation accuracy: 0.8361111283302307\n",
      "epoch: 29: train error: 0.29626759483168524, validation error: 1.173140048980713, validation accuracy: 0.8388888835906982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_80/782425250.py:30: UserWarning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (Triggered internally at ../torch/csrc/PyInterpreter.cpp:221.)\n",
      "  self.softmax_out = e_x / (torch.sum(e_x, dim=-1, keepdim=True) + 1e-10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30: train error: 0.2877894506479303, validation error: 1.1787556409835815, validation accuracy: 0.8305555582046509\n",
      "epoch: 31: train error: 0.27968938120951253, validation error: 1.1273820400238037, validation accuracy: 0.8388888835906982\n",
      "epoch: 32: train error: 0.27223343883330625, validation error: 1.1097760200500488, validation accuracy: 0.8444444537162781\n",
      "epoch: 33: train error: 0.26503761718049645, validation error: 1.1313735246658325, validation accuracy: 0.8444444537162781\n",
      "epoch: 34: train error: 0.2584956279024482, validation error: 1.1349374055862427, validation accuracy: 0.8527777791023254\n",
      "epoch: 35: train error: 0.2519673729936282, validation error: 1.0729708671569824, validation accuracy: 0.855555534362793\n",
      "epoch: 36: train error: 0.24622638849541545, validation error: 1.0988783836364746, validation accuracy: 0.8527777791023254\n",
      "epoch: 37: train error: 0.24063376849517226, validation error: 1.157753825187683, validation accuracy: 0.8527777791023254\n",
      "epoch: 38: train error: 0.23547349823638797, validation error: 1.065077304840088, validation accuracy: 0.8611111044883728\n",
      "epoch: 39: train error: 0.22980100583905974, validation error: 1.0723870992660522, validation accuracy: 0.8638888597488403\n",
      "epoch: 40: train error: 0.22592246842881045, validation error: 1.0279018878936768, validation accuracy: 0.8611111044883728\n",
      "epoch: 41: train error: 0.22154882767548165, validation error: 1.0422669649124146, validation accuracy: 0.8611111044883728\n",
      "epoch: 42: train error: 0.21697306570907435, validation error: 1.0377233028411865, validation accuracy: 0.8611111044883728\n",
      "epoch: 43: train error: 0.21232443349435925, validation error: 1.0674363374710083, validation accuracy: 0.8638888597488403\n",
      "epoch: 44: train error: 0.20913977657134333, validation error: 0.9911321997642517, validation accuracy: 0.875\n",
      "epoch: 45: train error: 0.20533996944626173, validation error: 1.0230680704116821, validation accuracy: 0.8722222447395325\n",
      "epoch: 46: train error: 0.20154767374818525, validation error: 0.9814561605453491, validation accuracy: 0.8777777552604675\n",
      "epoch: 47: train error: 0.19839350987846652, validation error: 1.0416804552078247, validation accuracy: 0.8638888597488403\n",
      "epoch: 48: train error: 0.19515012111514807, validation error: 1.0061477422714233, validation accuracy: 0.875\n",
      "epoch: 49: train error: 0.19232560057813922, validation error: 0.9647260308265686, validation accuracy: 0.8833333253860474\n",
      "epoch: 50: train error: 0.18917961744591594, validation error: 0.9787958860397339, validation accuracy: 0.8777777552604675\n",
      "epoch: 51: train error: 0.1862655064711968, validation error: 0.9670565128326416, validation accuracy: 0.8805555701255798\n",
      "epoch: 52: train error: 0.1837849943743398, validation error: 0.9688838720321655, validation accuracy: 0.8833333253860474\n",
      "epoch: 53: train error: 0.18107202493896088, validation error: 0.9771984815597534, validation accuracy: 0.8805555701255798\n",
      "epoch: 54: train error: 0.17811605411892137, validation error: 0.9775755405426025, validation accuracy: 0.8833333253860474\n",
      "epoch: 55: train error: 0.17556805070489645, validation error: 0.9381521344184875, validation accuracy: 0.8916666507720947\n",
      "epoch: 56: train error: 0.17314702117194733, validation error: 0.9498043656349182, validation accuracy: 0.8888888955116272\n",
      "epoch: 57: train error: 0.17044767388142645, validation error: 0.9451178908348083, validation accuracy: 0.8888888955116272\n",
      "epoch: 58: train error: 0.1685255067422986, validation error: 0.9693458676338196, validation accuracy: 0.8861111402511597\n",
      "epoch: 59: train error: 0.16613123465018967, validation error: 0.9628569483757019, validation accuracy: 0.8916666507720947\n",
      "epoch: 60: train error: 0.16413305738630393, validation error: 0.9224945306777954, validation accuracy: 0.894444465637207\n",
      "epoch: 61: train error: 0.16217321335958937, validation error: 0.9205269813537598, validation accuracy: 0.894444465637207\n",
      "epoch: 62: train error: 0.15991924338353178, validation error: 0.9302008748054504, validation accuracy: 0.894444465637207\n",
      "epoch: 63: train error: 0.15825045155361295, validation error: 0.9376702308654785, validation accuracy: 0.894444465637207\n",
      "epoch: 64: train error: 0.1562752596413096, validation error: 0.9148804545402527, validation accuracy: 0.8972222208976746\n",
      "epoch: 65: train error: 0.15347882104106247, validation error: 0.941471517086029, validation accuracy: 0.894444465637207\n",
      "epoch: 66: train error: 0.15220979725321135, validation error: 0.8953552842140198, validation accuracy: 0.8972222208976746\n",
      "epoch: 67: train error: 0.1505433600395918, validation error: 0.9152727127075195, validation accuracy: 0.8972222208976746\n",
      "epoch: 68: train error: 0.14862209224763015, validation error: 0.9064589738845825, validation accuracy: 0.894444465637207\n",
      "epoch: 69: train error: 0.14723751484416425, validation error: 0.915411651134491, validation accuracy: 0.8972222208976746\n",
      "epoch: 70: train error: 0.14510401152074337, validation error: 0.9067326188087463, validation accuracy: 0.8972222208976746\n",
      "epoch: 71: train error: 0.14409924360613027, validation error: 0.8972076177597046, validation accuracy: 0.8972222208976746\n",
      "epoch: 72: train error: 0.14256983863500258, validation error: 0.870868444442749, validation accuracy: 0.8972222208976746\n",
      "epoch: 73: train error: 0.14107163498799005, validation error: 0.8907076716423035, validation accuracy: 0.894444465637207\n",
      "epoch: 74: train error: 0.1397195680377384, validation error: 0.8783119320869446, validation accuracy: 0.8972222208976746\n",
      "epoch: 75: train error: 0.13752714009024203, validation error: 0.9016761183738708, validation accuracy: 0.8972222208976746\n",
      "epoch: 76: train error: 0.13667714805342257, validation error: 0.8947370648384094, validation accuracy: 0.8972222208976746\n",
      "epoch: 77: train error: 0.13455135317053646, validation error: 0.8556130528450012, validation accuracy: 0.9027777910232544\n",
      "epoch: 78: train error: 0.13376086732993522, validation error: 0.900648832321167, validation accuracy: 0.894444465637207\n",
      "epoch: 79: train error: 0.13221791378843287, validation error: 0.8723441958427429, validation accuracy: 0.8999999761581421\n",
      "epoch: 80: train error: 0.13120596817073724, validation error: 0.8400971293449402, validation accuracy: 0.9027777910232544\n",
      "epoch: 81: train error: 0.1297093778848648, validation error: 0.8748255372047424, validation accuracy: 0.8999999761581421\n",
      "epoch: 82: train error: 0.12867946697709462, validation error: 0.8818122148513794, validation accuracy: 0.8999999761581421\n",
      "epoch: 83: train error: 0.12736215915841362, validation error: 0.8635990619659424, validation accuracy: 0.8999999761581421\n",
      "epoch: 84: train error: 0.12637259322218597, validation error: 0.8804272413253784, validation accuracy: 0.8999999761581421\n",
      "epoch: 85: train error: 0.12480348884128034, validation error: 0.830580472946167, validation accuracy: 0.9055555462837219\n",
      "epoch: 86: train error: 0.12380301828185718, validation error: 0.8496103286743164, validation accuracy: 0.8999999761581421\n",
      "epoch: 87: train error: 0.122677717745925, validation error: 0.8566769361495972, validation accuracy: 0.8999999761581421\n",
      "epoch: 88: train error: 0.12182823514255385, validation error: 0.8450005650520325, validation accuracy: 0.8999999761581421\n",
      "epoch: 89: train error: 0.12040843620585899, validation error: 0.8506584167480469, validation accuracy: 0.9055555462837219\n",
      "epoch: 90: train error: 0.11979549440244834, validation error: 0.8340634107589722, validation accuracy: 0.9083333611488342\n",
      "epoch: 91: train error: 0.11842879195076723, validation error: 0.840910017490387, validation accuracy: 0.8999999761581421\n",
      "epoch: 92: train error: 0.11739674198906869, validation error: 0.8312790989875793, validation accuracy: 0.9027777910232544\n",
      "epoch: 93: train error: 0.11638023141616334, validation error: 0.8333303928375244, validation accuracy: 0.8999999761581421\n",
      "epoch: 94: train error: 0.11542256929290791, validation error: 0.8180862665176392, validation accuracy: 0.9055555462837219\n",
      "epoch: 95: train error: 0.11443402501754463, validation error: 0.8231669068336487, validation accuracy: 0.9055555462837219\n",
      "epoch: 96: train error: 0.11354883907673259, validation error: 0.8346832394599915, validation accuracy: 0.9027777910232544\n",
      "epoch: 97: train error: 0.11247264880997439, validation error: 0.797806978225708, validation accuracy: 0.9083333611488342\n",
      "epoch: 98: train error: 0.11142427334561944, validation error: 0.8360792398452759, validation accuracy: 0.8999999761581421\n",
      "epoch: 99: train error: 0.11074861360248178, validation error: 0.8086993098258972, validation accuracy: 0.9027777910232544\n"
     ]
    }
   ],
   "source": [
    "# ======モデル======\n",
    "class Linear():\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.W = torch.randn((out_features, in_features)) * torch.sqrt(torch.tensor(2.0 / in_features))\n",
    "        self.W.requires_grad = True\n",
    "        self.b = torch.zeros((1, out_features), requires_grad=True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.Z = X @ self.W.T + self.b\n",
    "        return self.Z\n",
    "\n",
    "    def backward(self, Z):\n",
    "        self.W.grad_ = Z.grad_.T @ self.X\n",
    "        self.b.grad_ = torch.sum(Z.grad_, dim=0)\n",
    "        self.X.grad_ = Z.grad_ @ self.W\n",
    "        return self.X.grad_\n",
    "\n",
    "class ReLU():\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        return X.clamp_min(0.)\n",
    "\n",
    "    def backward(self, A):\n",
    "        return A.grad_ * (self.X > 0).float()\n",
    "\n",
    "class SoftmaxCrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        e_x = torch.exp(X - torch.max(X, dim=-1, keepdim=True)[0])\n",
    "        self.softmax_out = e_x / (torch.sum(e_x, dim=-1, keepdim=True) + 1e-10)    \n",
    "        \n",
    "        log_probs = torch.log(self.softmax_out + 1e-10)\n",
    "        target_log_probs = log_probs * y\n",
    "\n",
    "        self.loss = -target_log_probs.sum(dim=-1).mean()\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, y):\n",
    "        return (self.softmax_out - y) / y.shape[0]\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, input_features, hidden_units, output_units):\n",
    "        self.linear1 = Linear(input_features, hidden_units)\n",
    "        self.relu = ReLU()\n",
    "        self.linear2 = Linear(hidden_units, output_units)\n",
    "        self.loss_fn = SoftmaxCrossEntropy()\n",
    "        \n",
    "    def forward(self, X, y):\n",
    "        self.X = X\n",
    "        self.Z1 = self.linear1.forward(X)\n",
    "        self.A1 = self.relu.forward(self.Z1)\n",
    "        self.Z2 = self.linear2.forward(self.A1)\n",
    "        self.loss = self.loss_fn.forward(self.Z2, y)\n",
    "        return self.loss, self.Z2\n",
    "    \n",
    "    def backward(self, y):\n",
    "        self.Z2.grad_ = self.loss_fn.backward(y)\n",
    "        self.A1.grad_ = self.linear2.backward(self.Z2)\n",
    "        self.Z1.grad_ = self.relu.backward(self.A1)\n",
    "        self.X.grad_ = self.linear1.backward(self.Z1)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        # 勾配の初期化\n",
    "        self.linear1.W.grad_ = None\n",
    "        self.linear1.b.grad_ = None\n",
    "        self.linear2.W.grad_ = None\n",
    "        self.linear2.b.grad_ = None\n",
    "        \n",
    "    def step(self, learning_rate):\n",
    "        # パラメータの更新\n",
    "        self.linear1.W -= learning_rate * self.linear1.W.grad_\n",
    "        self.linear1.b -= learning_rate * self.linear1.b.grad_\n",
    "        self.linear2.W -= learning_rate * self.linear2.W.grad_\n",
    "        self.linear2.b -= learning_rate * self.linear2.b.grad_\n",
    "\n",
    "## Refactoring後の学習ループ(OptimizerやDataset, Dataloaderは後ほどRefactoring)\n",
    "# ===データの準備====\n",
    "dataset = datasets.load_digits()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "images = dataset['images']\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size=0.2, random_state=42)\n",
    "X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "X_val = (X_val - X_train.mean()) / X_train.std()\n",
    "X_train = torch.tensor(X_train.reshape(-1, 64), dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val.reshape(-1, 64), dtype=torch.float32)\n",
    "y_train = F.one_hot(torch.tensor(y_train), num_classes=10) #1437 x 10 \n",
    "y_val = F.one_hot(torch.tensor(y_val), num_classes=10) # 360 x 10\n",
    "batch_size = 30\n",
    "# モデルの初期化\n",
    "model = Model(input_features=64, hidden_units=10, output_units=10)\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# ログ\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "for epoch in range(100):\n",
    "    # エポック毎にデータをシャッフル\n",
    "    shuffled_indices = np.random.permutation(len(y_train))\n",
    "    num_batches = np.ceil(len(y_train)/batch_size).astype(int)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        \n",
    "        # mini batch作成\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        batch_indices = shuffled_indices[start:end]\n",
    "        y_true_ = y_train[batch_indices, :] # batch_size x 10\n",
    "        \n",
    "        X = X_train[batch_indices] # batch_size x 64\n",
    "        # 順伝播と逆伝播の計算\n",
    "        loss, _ = model.forward(X, y_true_)\n",
    "        model.backward(y_true_)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # パラメータ更新\n",
    "        with torch.no_grad():\n",
    "            model.step(learning_rate)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        val_loss, Z2_val = model.forward(X_val, y_val)\n",
    "        \n",
    "        val_accuracy = torch.sum(torch.argmax(Z2_val, dim=-1) == torch.argmax(y_val, dim=-1)) / y_val.shape[0]\n",
    "\n",
    "    train_losses.append(running_loss/num_batches)\n",
    "    val_losses.append(val_loss.item())\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f'epoch: {epoch}: train error: {running_loss/num_batches}, validation error: {val_loss.item()}, validation accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365ce93-a0d9-40cc-98f9-c39ce9c700e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
