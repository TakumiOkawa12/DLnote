{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010067b2-79fb-4b41-8ddc-8d288b2a14b8",
   "metadata": {},
   "source": [
    "# saveとload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c2c29-b9cd-4f2a-9c05-5bc4a7e19f5e",
   "metadata": {},
   "source": [
    "## early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071eec2f-848b-41ad-8555-857c60c00994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e92dc3ad-9373-4715-a5a0-df60c245fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y, transform = None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        return X, y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_in, num_hidden, num_out):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten(1, -1)\n",
    "        self.l1 = nn.Linear(num_in, num_hidden) # 隠れ層(第1層)を定義\n",
    "        self.l2 = nn.Linear(num_hidden, num_out) # 隠れ層(第2層)を定義\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        # z1 = self.l1(x) \n",
    "        # a1 = F.relu(z1)\n",
    "        # z2 = self.l2(a1)\n",
    "        x = self.l2(F.relu(self.l1(x)))\n",
    "        return x\n",
    "\n",
    "def learn(model, train_loader, val_loader, opt, loss_func, num_epoch, early_stopping = None):\n",
    "    # ログ\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    # early_stopping_counter\n",
    "    no_improve = 0\n",
    "    \n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    # モデル学習\n",
    "    for epoch in range(num_epoch):\n",
    "        running_loss = 0\n",
    "        running_val_loss = 0\n",
    "        running_val_accuracy = 0\n",
    "        \n",
    "        for train_batch, data in enumerate(train_loader):\n",
    "    \n",
    "            X, y = data\n",
    "            opt.zero_grad() # 勾配初期化\n",
    "            # forward\n",
    "            preds = model(X)\n",
    "            loss = loss_func(preds, y)\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "            # backward\n",
    "            loss.backward()\n",
    "            opt.step() # パラメータ更新\n",
    "            \n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for val_batch, data in enumerate(val_loader):\n",
    "                X_val, y_val = data\n",
    "                preds_val = model(X_val)\n",
    "                val_loss = loss_func(preds_val, y_val)\n",
    "                running_val_loss += val_loss.item()\n",
    "                val_accuracy = torch.sum(torch.argmax(preds_val, dim = -1) == y_val) / y_val.shape[0]\n",
    "                running_val_accuracy += val_accuracy.item()\n",
    "    \n",
    "        train_losses.append(running_loss / (train_batch + 1))\n",
    "        val_losses.append(running_val_loss / (val_batch + 1))\n",
    "        val_accuracies.append(running_val_accuracy / (val_batch + 1))\n",
    "        print(f'epoch:{epoch}, train error:{train_losses[-1]}, val_losses:{val_losses[-1]}, val_accuracy:{val_accuracies[-1]}')\n",
    "        if val_losses[-1] < best_val_loss:\n",
    "            no_improve = 0\n",
    "            best_val_loss = val_losses[-1]\n",
    "        else:\n",
    "            no_improve += 1\n",
    "        if early_stopping and no_improve >= early_stopping:\n",
    "            print(\"stop training because val loss don't improve anymore\")\n",
    "            break\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cfd3bf7-f0fc-4ede-be96-9ef3880ee15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train error:2.1843870057000054, val_losses:2.0654842456181846, val_accuracy:0.4036458333333333\n",
      "epoch:1, train error:1.866288505660163, val_losses:1.7236454288164775, val_accuracy:0.6328125\n",
      "epoch:2, train error:1.476594238811069, val_losses:1.3486510713895161, val_accuracy:0.7317708333333334\n",
      "epoch:3, train error:1.099349820613861, val_losses:1.0151362419128418, val_accuracy:0.8463541666666666\n",
      "epoch:4, train error:0.8169830269283719, val_losses:0.7726800094048182, val_accuracy:0.9010416666666666\n",
      "epoch:5, train error:0.6271594590610928, val_losses:0.6124205912152926, val_accuracy:0.921875\n",
      "epoch:6, train error:0.506532926691903, val_losses:0.5097397714853287, val_accuracy:0.9348958333333334\n",
      "epoch:7, train error:0.421243777539995, val_losses:0.442648025850455, val_accuracy:0.9296875\n",
      "epoch:8, train error:0.36365310847759247, val_losses:0.3789863313237826, val_accuracy:0.9348958333333334\n",
      "epoch:9, train error:0.3212355573972066, val_losses:0.34919851397474605, val_accuracy:0.9348958333333334\n",
      "epoch:10, train error:0.2890826384226481, val_losses:0.3129697075734536, val_accuracy:0.9479166666666666\n",
      "epoch:11, train error:0.2635777635706796, val_losses:0.28920906223356724, val_accuracy:0.9505208333333334\n",
      "epoch:12, train error:0.24269403864940006, val_losses:0.2713810633867979, val_accuracy:0.953125\n",
      "epoch:13, train error:0.22604381326172088, val_losses:0.2584571323047082, val_accuracy:0.9505208333333334\n",
      "epoch:14, train error:0.21146823035346138, val_losses:0.24315171192089716, val_accuracy:0.953125\n",
      "epoch:15, train error:0.19910885840654374, val_losses:0.22557111425946155, val_accuracy:0.9583333333333334\n",
      "epoch:16, train error:0.18809692958990734, val_losses:0.2224888326600194, val_accuracy:0.9583333333333334\n",
      "epoch:17, train error:0.17843650066190295, val_losses:0.21034359652549028, val_accuracy:0.9635416666666666\n",
      "epoch:18, train error:0.17009591857592266, val_losses:0.20158249388138452, val_accuracy:0.9661458333333334\n",
      "epoch:19, train error:0.1624185728530089, val_losses:0.1965321988488237, val_accuracy:0.9635416666666666\n",
      "epoch:20, train error:0.15638764633072746, val_losses:0.1907361432289084, val_accuracy:0.9609375\n",
      "epoch:21, train error:0.15150742009282112, val_losses:0.1849131422738234, val_accuracy:0.9635416666666666\n",
      "epoch:22, train error:0.14525942761037086, val_losses:0.17890840799858174, val_accuracy:0.9661458333333334\n",
      "epoch:23, train error:0.14037613992889722, val_losses:0.17365765882035097, val_accuracy:0.9661458333333334\n",
      "epoch:24, train error:0.1348913271807962, val_losses:0.17246936758359274, val_accuracy:0.9713541666666666\n",
      "epoch:25, train error:0.13069389396243625, val_losses:0.16475575867419442, val_accuracy:0.9713541666666666\n",
      "epoch:26, train error:0.12686827149656082, val_losses:0.16076501738280058, val_accuracy:0.9661458333333334\n",
      "epoch:27, train error:0.12278197631239891, val_losses:0.1599983487588664, val_accuracy:0.96875\n",
      "epoch:28, train error:0.1188624066611131, val_losses:0.15804056512812772, val_accuracy:0.9661458333333334\n",
      "epoch:29, train error:0.11570579964253637, val_losses:0.1534590187172095, val_accuracy:0.9661458333333334\n",
      "epoch:30, train error:0.11276234322124057, val_losses:0.15334762694935003, val_accuracy:0.9713541666666666\n",
      "epoch:31, train error:0.10967670364512337, val_losses:0.1521973667355875, val_accuracy:0.96875\n",
      "epoch:32, train error:0.10646529495716095, val_losses:0.15111317997798324, val_accuracy:0.96875\n",
      "epoch:33, train error:0.10378793593910006, val_losses:0.14614979891727367, val_accuracy:0.9713541666666666\n",
      "epoch:34, train error:0.10202495422628191, val_losses:0.1436032842223843, val_accuracy:0.9739583333333334\n",
      "epoch:35, train error:0.0989339513083299, val_losses:0.14307266489292184, val_accuracy:0.96875\n",
      "epoch:36, train error:0.09668477483921581, val_losses:0.1424467150742809, val_accuracy:0.96875\n",
      "epoch:37, train error:0.09415081549021932, val_losses:0.1394669672784706, val_accuracy:0.96875\n",
      "epoch:38, train error:0.0931322521633572, val_losses:0.13892121923466524, val_accuracy:0.9661458333333334\n",
      "epoch:39, train error:0.090374563054906, val_losses:0.1366634009561191, val_accuracy:0.9661458333333334\n",
      "epoch:40, train error:0.08806467312905523, val_losses:0.13582039826239148, val_accuracy:0.96875\n",
      "epoch:41, train error:0.08698465666837163, val_losses:0.1356009248799334, val_accuracy:0.96875\n",
      "epoch:42, train error:0.08498474475410249, val_losses:0.1357259762007743, val_accuracy:0.96875\n",
      "epoch:43, train error:0.0828844792313046, val_losses:0.13410508718031147, val_accuracy:0.96875\n",
      "epoch:44, train error:0.08043940799931686, val_losses:0.13456668402068317, val_accuracy:0.96875\n",
      "epoch:45, train error:0.0800309006538656, val_losses:0.13180016501185796, val_accuracy:0.9713541666666666\n",
      "epoch:46, train error:0.07801920593612724, val_losses:0.13122388487681746, val_accuracy:0.96875\n",
      "epoch:47, train error:0.07688309881422255, val_losses:0.1317937735002488, val_accuracy:0.9661458333333334\n",
      "epoch:48, train error:0.07522804944051636, val_losses:0.1295435578407099, val_accuracy:0.96875\n",
      "epoch:49, train error:0.07355117578473357, val_losses:0.12891065934672952, val_accuracy:0.96875\n",
      "epoch:50, train error:0.07252178481883473, val_losses:0.1307517075135062, val_accuracy:0.9635416666666666\n",
      "epoch:51, train error:0.07119413415590922, val_losses:0.12906857028913996, val_accuracy:0.9635416666666666\n",
      "epoch:52, train error:0.0694095529615879, val_losses:0.12860674217032889, val_accuracy:0.9661458333333334\n",
      "epoch:53, train error:0.06895247681273355, val_losses:0.1287284140319874, val_accuracy:0.9661458333333334\n",
      "epoch:54, train error:0.06708529674344593, val_losses:0.12751824082806706, val_accuracy:0.96875\n",
      "epoch:55, train error:0.0660793019251691, val_losses:0.12695415628453097, val_accuracy:0.96875\n",
      "epoch:56, train error:0.06478267361720404, val_losses:0.12812502697731057, val_accuracy:0.9661458333333334\n",
      "epoch:57, train error:0.06435490672787031, val_losses:0.1255705754738301, val_accuracy:0.9635416666666666\n",
      "epoch:58, train error:0.06338802095916536, val_losses:0.12527148937806487, val_accuracy:0.9635416666666666\n",
      "epoch:59, train error:0.06203996485306157, val_losses:0.1253741132095456, val_accuracy:0.9635416666666666\n",
      "epoch:60, train error:0.060873429808351726, val_losses:0.12678636649313071, val_accuracy:0.9661458333333334\n",
      "epoch:61, train error:0.06044432371854782, val_losses:0.12468595243990421, val_accuracy:0.9635416666666666\n",
      "epoch:62, train error:0.05932681560516358, val_losses:0.12521271081641316, val_accuracy:0.9661458333333334\n",
      "epoch:63, train error:0.0579765046429303, val_losses:0.12353063561022282, val_accuracy:0.9635416666666666\n",
      "epoch:64, train error:0.057559581742518476, val_losses:0.1238143452598403, val_accuracy:0.9661458333333334\n",
      "epoch:65, train error:0.05671634500225385, val_losses:0.12344844988547266, val_accuracy:0.9661458333333334\n",
      "epoch:66, train error:0.05604183626257711, val_losses:0.12455401266925037, val_accuracy:0.96875\n",
      "epoch:67, train error:0.05498223135040866, val_losses:0.12413762540866931, val_accuracy:0.9661458333333334\n",
      "epoch:68, train error:0.053622992554058634, val_losses:0.12326355860568583, val_accuracy:0.9635416666666666\n",
      "epoch:69, train error:0.05300657943718963, val_losses:0.12536456466962895, val_accuracy:0.9635416666666666\n",
      "epoch:70, train error:0.05328182607061333, val_losses:0.12312845637400945, val_accuracy:0.96875\n",
      "epoch:71, train error:0.05170914629060361, val_losses:0.12187758375269671, val_accuracy:0.9661458333333334\n",
      "epoch:72, train error:0.05134174610591597, val_losses:0.12313971963400643, val_accuracy:0.9661458333333334\n",
      "epoch:73, train error:0.05072499509486887, val_losses:0.12158208899199963, val_accuracy:0.9661458333333334\n",
      "epoch:74, train error:0.049905832691325085, val_losses:0.12216026134168108, val_accuracy:0.9635416666666666\n",
      "epoch:75, train error:0.04913803152740002, val_losses:0.12110208432811002, val_accuracy:0.9661458333333334\n",
      "epoch:76, train error:0.04835293404757977, val_losses:0.12129299660834174, val_accuracy:0.9635416666666666\n",
      "epoch:77, train error:0.048334638215601446, val_losses:0.12251583316052954, val_accuracy:0.9635416666666666\n",
      "epoch:78, train error:0.047206537218557464, val_losses:0.12278845300897956, val_accuracy:0.9609375\n",
      "epoch:79, train error:0.046882647834718225, val_losses:0.12286419336063166, val_accuracy:0.9635416666666666\n",
      "epoch:80, train error:0.04585852985166841, val_losses:0.12195712979882956, val_accuracy:0.9635416666666666\n",
      "stop training because val loss don't improve anymore\n"
     ]
    }
   ],
   "source": [
    "# データ準備\n",
    "dataset = datasets.load_digits()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "images = dataset['images']\n",
    "images = images * (255. / 16.) # 0~16 -> 0~255\n",
    "images = images.astype(np.uint8)\n",
    "# 学習データと検証データの作成\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size = 0.2, random_state = 0)\n",
    "# DatasetとDataLoaderの作成\n",
    "batch_size = 32\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = MyDataset(X_train, y_train, transform = transform)\n",
    "val_dataset = MyDataset(X_val, y_val, transform = transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, num_workers = 2)\n",
    "# モデルの初期化\n",
    "model = MLP(64, 30, 10)\n",
    "# optimizerの定義\n",
    "opt = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "learning_rate = 0.03\n",
    "\n",
    "train_losses, val_losses, val_accuracies = learn(model, train_loader, val_loader, opt = opt, loss_func = F.cross_entropy, num_epoch = 1000, early_stopping=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf75654-09aa-4032-8269-6f7946533770",
   "metadata": {},
   "source": [
    "## モデルオブジェクトの保存とロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa8d54ae-5a4e-4be1-acbd-0d7cf36abe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'sample_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15822ed9-7b97-4856-8ebf-94cdaf47c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load('sample_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da4341c0-69af-4677-89f3-859814850eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (l1): Linear(in_features=64, out_features=30, bias=True)\n",
       "  (l2): Linear(in_features=30, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4244547f-799d-4eee-baf6-0cfbf2a70dc9",
   "metadata": {},
   "source": [
    "## モデルパラメータの保存とロード\n",
    "- モデルのオブジェクトを保存するよりモデルパラメータを保存することが推奨されている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97660deb-2f09-4332-aa91-3ebfc6069a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.state_dict() # .parameters()はパラメータのイテレータを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f23679be-6854-4882-bc02-bdd5b9670dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "another_model = MLP(64, 30, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ee1bea8-3c47-4100-a3e8-1aefce95c3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3065d52b-fb7d-46cd-8308-ce42bc109a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1282e-01, -6.3440e-02,  7.6734e-02,  ..., -4.8236e-02,\n",
       "          7.9601e-02, -8.7400e-02],\n",
       "        [ 5.9361e-02, -1.7456e-04,  1.8106e-01,  ...,  1.0305e-01,\n",
       "          8.9167e-02,  4.8587e-03],\n",
       "        [ 6.1278e-03, -1.2902e-01,  7.3366e-02,  ...,  6.2912e-03,\n",
       "          9.6055e-02,  7.9921e-02],\n",
       "        ...,\n",
       "        [-1.9209e-01, -8.3390e-02, -2.9702e-01,  ...,  2.4603e-02,\n",
       "          3.7131e-02,  1.3476e-01],\n",
       "        [-1.8528e-01, -5.5052e-02,  4.7711e-02,  ...,  5.0124e-01,\n",
       "          6.0677e-02,  9.4646e-02],\n",
       "        [-1.1786e-01, -1.3595e-01,  7.4357e-02,  ..., -8.5267e-02,\n",
       "         -1.3104e-01, -1.6461e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f61411f8-0f16-4c75-b641-d32f60f49014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1282e-01, -6.3440e-02,  7.6734e-02,  ..., -4.8236e-02,\n",
       "          7.9601e-02, -8.7400e-02],\n",
       "        [ 5.9361e-02, -1.7456e-04,  1.8106e-01,  ...,  1.0305e-01,\n",
       "          8.9167e-02,  4.8587e-03],\n",
       "        [ 6.1278e-03, -1.2902e-01,  7.3366e-02,  ...,  6.2912e-03,\n",
       "          9.6055e-02,  7.9921e-02],\n",
       "        ...,\n",
       "        [-1.9209e-01, -8.3390e-02, -2.9702e-01,  ...,  2.4603e-02,\n",
       "          3.7131e-02,  1.3476e-01],\n",
       "        [-1.8528e-01, -5.5052e-02,  4.7711e-02,  ...,  5.0124e-01,\n",
       "          6.0677e-02,  9.4646e-02],\n",
       "        [-1.1786e-01, -1.3595e-01,  7.4357e-02,  ..., -8.5267e-02,\n",
       "         -1.3104e-01, -1.6461e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_model.l1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24f3dc88-8860-4aae-ba2a-9045defaf9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'sample_model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "300aaf35-1453-4a9b-93ba-160471fbc2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_model.load_state_dict(torch.load('sample_model_state_dict.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a54250a-2671-4ec8-83b5-25e97b39451b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {0: {'momentum_buffer': None},\n",
       "  1: {'momentum_buffer': None},\n",
       "  2: {'momentum_buffer': None},\n",
       "  3: {'momentum_buffer': None}},\n",
       " 'param_groups': [{'lr': 0.03,\n",
       "   'momentum': 0,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'maximize': False,\n",
       "   'foreach': None,\n",
       "   'differentiable': False,\n",
       "   'params': [0, 1, 2, 3]}]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9aacd9-0c48-45ba-8a79-96f4ffc09769",
   "metadata": {},
   "source": [
    "## 学習ループ中に最良のモデルを保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "643a0b27-9216-4328-9407-716520e27e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y, transform = None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        return X, y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_in, num_hidden, num_out):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten(1, -1)\n",
    "        self.l1 = nn.Linear(num_in, num_hidden) # 隠れ層(第1層)を定義\n",
    "        self.l2 = nn.Linear(num_hidden, num_out) # 隠れ層(第2層)を定義\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        # z1 = self.l1(x) \n",
    "        # a1 = F.relu(z1)\n",
    "        # z2 = self.l2(a1)\n",
    "        x = self.l2(F.relu(self.l1(x)))\n",
    "        return x\n",
    "\n",
    "def learn(model, train_loader, val_loader, opt, loss_func, num_epoch, early_stopping = None, save_path = None):\n",
    "    # ログ\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    # early_stopping_counter\n",
    "    no_improve = 0\n",
    "    \n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    # モデル学習\n",
    "    for epoch in range(num_epoch):\n",
    "        running_loss = 0\n",
    "        running_val_loss = 0\n",
    "        running_val_accuracy = 0\n",
    "        \n",
    "        for train_batch, data in enumerate(train_loader):\n",
    "    \n",
    "            X, y = data\n",
    "            opt.zero_grad() # 勾配初期化\n",
    "            # forward\n",
    "            preds = model(X)\n",
    "            loss = loss_func(preds, y)\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "            # backward\n",
    "            loss.backward()\n",
    "            opt.step() # パラメータ更新\n",
    "            \n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for val_batch, data in enumerate(val_loader):\n",
    "                X_val, y_val = data\n",
    "                preds_val = model(X_val)\n",
    "                val_loss = loss_func(preds_val, y_val)\n",
    "                running_val_loss += val_loss.item()\n",
    "                val_accuracy = torch.sum(torch.argmax(preds_val, dim = -1) == y_val) / y_val.shape[0]\n",
    "                running_val_accuracy += val_accuracy.item()\n",
    "    \n",
    "        train_losses.append(running_loss / (train_batch + 1))\n",
    "        val_losses.append(running_val_loss / (val_batch + 1))\n",
    "        val_accuracies.append(running_val_accuracy / (val_batch + 1))\n",
    "        print(f'epoch:{epoch}, train error:{train_losses[-1]}, val_losses:{val_losses[-1]}, val_accuracy:{val_accuracies[-1]}')\n",
    "        if val_losses[-1] < best_val_loss:\n",
    "            no_improve = 0\n",
    "            best_val_loss = val_losses[-1]\n",
    "            best_model = model\n",
    "        else:\n",
    "            no_improve += 1\n",
    "        if early_stopping and no_improve >= early_stopping:\n",
    "            print(\"stop training because val loss don't improve anymore\")\n",
    "            if save_path:\n",
    "                torch.save({'model_parameter' : best_model.state_dict(), 'opt_parameter' : opt.state_dict(), 'val_loss' : best_val_loss}, save_path)\n",
    "            break\n",
    "\n",
    "    if save_path:\n",
    "        torch.save({'model_parameter' : best_model.state_dict(), 'opt_parameter' : opt.state_dict(), 'val_loss' : best_val_loss}, save_path)\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "364abc00-254f-4ab0-b0c8-330663ec5fd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train error:2.2394752979278563, val_losses:2.1214182376861572, val_accuracy:0.2942708333333333\n",
      "epoch:1, train error:1.946669496430291, val_losses:1.798375556866328, val_accuracy:0.6171875\n",
      "epoch:2, train error:1.5539350509643555, val_losses:1.3932238121827443, val_accuracy:0.7630208333333334\n",
      "epoch:3, train error:1.158011163605584, val_losses:1.0601645509401958, val_accuracy:0.8098958333333334\n",
      "epoch:4, train error:0.8614217082659403, val_losses:0.8103910237550735, val_accuracy:0.8776041666666666\n",
      "epoch:5, train error:0.6634238587485419, val_losses:0.6546802371740341, val_accuracy:0.8854166666666666\n",
      "epoch:6, train error:0.5366636315981547, val_losses:0.5372151459256808, val_accuracy:0.9244791666666666\n",
      "epoch:7, train error:0.44715239604314166, val_losses:0.4701428363720576, val_accuracy:0.8932291666666666\n",
      "epoch:8, train error:0.3863742378022936, val_losses:0.4113098258773486, val_accuracy:0.9322916666666666\n",
      "epoch:9, train error:0.34036011265383825, val_losses:0.3672925891975562, val_accuracy:0.9322916666666666\n",
      "epoch:10, train error:0.3040200776524014, val_losses:0.3373386301100254, val_accuracy:0.9401041666666666\n",
      "epoch:11, train error:0.27621007578240503, val_losses:0.3067541445295016, val_accuracy:0.9427083333333334\n",
      "epoch:12, train error:0.2538611817691061, val_losses:0.2859455111126105, val_accuracy:0.9401041666666666\n",
      "epoch:13, train error:0.23468128972583346, val_losses:0.2738604961584012, val_accuracy:0.9322916666666666\n",
      "epoch:14, train error:0.21779718862639533, val_losses:0.25468174119790393, val_accuracy:0.9453125\n",
      "epoch:15, train error:0.20555520554383597, val_losses:0.24243710500498614, val_accuracy:0.9479166666666666\n",
      "epoch:16, train error:0.1934582499994172, val_losses:0.23064479231834412, val_accuracy:0.9479166666666666\n",
      "epoch:17, train error:0.18398118333684074, val_losses:0.21824597443143526, val_accuracy:0.9557291666666666\n",
      "epoch:18, train error:0.17415616164604822, val_losses:0.20874359489729008, val_accuracy:0.9505208333333334\n",
      "epoch:19, train error:0.16710031479597093, val_losses:0.20211729779839516, val_accuracy:0.9609375\n",
      "epoch:20, train error:0.1590687010023329, val_losses:0.19667469306538501, val_accuracy:0.9609375\n",
      "epoch:21, train error:0.1523946618868245, val_losses:0.19195826072245836, val_accuracy:0.9557291666666666\n",
      "epoch:22, train error:0.14784451375404994, val_losses:0.18411105933288732, val_accuracy:0.9609375\n",
      "epoch:23, train error:0.1425760966208246, val_losses:0.1843678898488482, val_accuracy:0.9557291666666666\n",
      "epoch:24, train error:0.13648345006836785, val_losses:0.17994367548575005, val_accuracy:0.9557291666666666\n",
      "epoch:25, train error:0.13138554319739343, val_losses:0.17244008742272854, val_accuracy:0.9635416666666666\n",
      "epoch:26, train error:0.12805879389246305, val_losses:0.17102613362173238, val_accuracy:0.9609375\n",
      "epoch:27, train error:0.12364088905354341, val_losses:0.16910762122521797, val_accuracy:0.9609375\n",
      "epoch:28, train error:0.11976241837773058, val_losses:0.16723017363498607, val_accuracy:0.9583333333333334\n",
      "epoch:29, train error:0.11630210454265276, val_losses:0.1610939564804236, val_accuracy:0.9635416666666666\n",
      "epoch:30, train error:0.11324846177465386, val_losses:0.15875276581694683, val_accuracy:0.9635416666666666\n",
      "epoch:31, train error:0.10996625978085729, val_losses:0.16288798892249665, val_accuracy:0.9609375\n",
      "epoch:32, train error:0.10766633169518577, val_losses:0.15849619762351116, val_accuracy:0.9609375\n",
      "epoch:33, train error:0.10559714626934794, val_losses:0.1554810325615108, val_accuracy:0.9635416666666666\n",
      "epoch:34, train error:0.10228952459163136, val_losses:0.15383155069624385, val_accuracy:0.9661458333333334\n",
      "epoch:35, train error:0.09955998576349682, val_losses:0.1517691295593977, val_accuracy:0.9661458333333334\n",
      "epoch:36, train error:0.09724687718682819, val_losses:0.15061227759967247, val_accuracy:0.9661458333333334\n",
      "epoch:37, train error:0.09539142060610983, val_losses:0.1479302840307355, val_accuracy:0.9661458333333334\n",
      "epoch:38, train error:0.09291233370701472, val_losses:0.14806015805030862, val_accuracy:0.9635416666666666\n",
      "epoch:39, train error:0.09111707084294822, val_losses:0.14413325364391008, val_accuracy:0.9661458333333334\n",
      "epoch:40, train error:0.09014166005783611, val_losses:0.14244896654660502, val_accuracy:0.9661458333333334\n",
      "epoch:41, train error:0.08735385230845875, val_losses:0.14269531766573587, val_accuracy:0.9661458333333334\n",
      "epoch:42, train error:0.08506971092687712, val_losses:0.1453392500989139, val_accuracy:0.9661458333333334\n",
      "epoch:43, train error:0.08380600528584586, val_losses:0.14143412575746575, val_accuracy:0.9635416666666666\n",
      "epoch:44, train error:0.08275578030281597, val_losses:0.14113616570830345, val_accuracy:0.9661458333333334\n",
      "epoch:45, train error:0.08062084350321028, val_losses:0.14277707117920121, val_accuracy:0.9609375\n",
      "epoch:46, train error:0.07942377881457409, val_losses:0.14213476966445646, val_accuracy:0.9635416666666666\n",
      "epoch:47, train error:0.07801616576810678, val_losses:0.13911901911099753, val_accuracy:0.9609375\n",
      "epoch:48, train error:0.07667990409665637, val_losses:0.13869615357058743, val_accuracy:0.9635416666666666\n",
      "epoch:49, train error:0.07462438195943832, val_losses:0.13680712956314287, val_accuracy:0.9661458333333334\n",
      "epoch:50, train error:0.07380396388471126, val_losses:0.13743984800142547, val_accuracy:0.9635416666666666\n",
      "epoch:51, train error:0.07279458240502411, val_losses:0.13831794199844202, val_accuracy:0.9635416666666666\n",
      "epoch:52, train error:0.07106221057474613, val_losses:0.13757150488284728, val_accuracy:0.9661458333333334\n",
      "epoch:53, train error:0.07029315696822272, val_losses:0.13528850263295075, val_accuracy:0.9609375\n",
      "epoch:54, train error:0.06957573754092057, val_losses:0.1355592447022597, val_accuracy:0.9609375\n",
      "epoch:55, train error:0.06787682837910122, val_losses:0.13433178382304808, val_accuracy:0.9635416666666666\n",
      "epoch:56, train error:0.06682934879014889, val_losses:0.13603530932838717, val_accuracy:0.9635416666666666\n",
      "epoch:57, train error:0.06595210457841555, val_losses:0.13410939501288036, val_accuracy:0.9635416666666666\n",
      "epoch:58, train error:0.06480733737763432, val_losses:0.13403332396410406, val_accuracy:0.9635416666666666\n",
      "epoch:59, train error:0.06359293320112758, val_losses:0.13405698157536486, val_accuracy:0.9661458333333334\n",
      "epoch:60, train error:0.0626868340290255, val_losses:0.13244641378211477, val_accuracy:0.9635416666666666\n",
      "epoch:61, train error:0.061847730663915475, val_losses:0.1355049677658826, val_accuracy:0.9609375\n",
      "epoch:62, train error:0.06121326866042283, val_losses:0.13266366386475661, val_accuracy:0.9661458333333334\n",
      "epoch:63, train error:0.06009698590884606, val_losses:0.13377896153057614, val_accuracy:0.9635416666666666\n",
      "epoch:64, train error:0.059029923379421236, val_losses:0.13204713398590684, val_accuracy:0.9661458333333334\n",
      "epoch:65, train error:0.05820153715709845, val_losses:0.13299890514463186, val_accuracy:0.9635416666666666\n",
      "epoch:66, train error:0.057831139821145267, val_losses:0.1322732816915959, val_accuracy:0.9635416666666666\n",
      "epoch:67, train error:0.05667876572244697, val_losses:0.13233769855772456, val_accuracy:0.9635416666666666\n",
      "epoch:68, train error:0.05609611365944147, val_losses:0.13275790315431854, val_accuracy:0.9635416666666666\n",
      "epoch:69, train error:0.054933626039160625, val_losses:0.13023250255112848, val_accuracy:0.9635416666666666\n",
      "epoch:70, train error:0.054415421312054, val_losses:0.13268562328691283, val_accuracy:0.9635416666666666\n",
      "epoch:71, train error:0.054111433919105265, val_losses:0.1313583399169147, val_accuracy:0.9635416666666666\n",
      "epoch:72, train error:0.05338560804310772, val_losses:0.13039630961914858, val_accuracy:0.9661458333333334\n",
      "epoch:73, train error:0.052093172466589344, val_losses:0.13056999530332783, val_accuracy:0.9609375\n",
      "epoch:74, train error:0.051218718931906757, val_losses:0.1322986267041415, val_accuracy:0.9635416666666666\n",
      "stop training because val loss don't improve anymore\n"
     ]
    }
   ],
   "source": [
    "# データ準備\n",
    "dataset = datasets.load_digits()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "images = dataset['images']\n",
    "images = images * (255. / 16.) # 0~16 -> 0~255\n",
    "images = images.astype(np.uint8)\n",
    "# 学習データと検証データの作成\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size = 0.2, random_state = 0)\n",
    "# DatasetとDataLoaderの作成\n",
    "batch_size = 32\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = MyDataset(X_train, y_train, transform = transform)\n",
    "val_dataset = MyDataset(X_val, y_val, transform = transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, num_workers = 2)\n",
    "# モデルの初期化\n",
    "model = MLP(64, 30, 10)\n",
    "# optimizerの定義\n",
    "opt = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "learning_rate = 0.03\n",
    "\n",
    "train_losses, val_losses, val_accuracies = learn(model, train_loader, val_loader, opt = opt, loss_func = F.cross_entropy, num_epoch = 1000, early_stopping=5, save_path = 'checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab05b23f-8f56-4bd9-aad4-0b913a7ee31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dict = torch.load('checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12b8439d-1dce-4615-b4ec-edb87a97b893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_parameter': OrderedDict([('l1.weight',\n",
       "               tensor([[-0.0242, -0.1255, -0.0174,  ...,  0.0572,  0.0815,  0.0332],\n",
       "                       [ 0.0369, -0.0697,  0.0556,  ..., -0.0340,  0.1218,  0.1237],\n",
       "                       [-0.0819, -0.0244,  0.0521,  ..., -0.0984,  0.1144, -0.0518],\n",
       "                       ...,\n",
       "                       [-0.1152, -0.1422, -0.3021,  ...,  0.2067,  0.0325, -0.0742],\n",
       "                       [-0.1323, -0.2531, -0.3395,  ..., -0.1320, -0.1352, -0.0737],\n",
       "                       [-0.1395, -0.1404, -0.0083,  ..., -0.0617,  0.0605, -0.0538]])),\n",
       "              ('l1.bias',\n",
       "               tensor([ 0.0377,  0.0483,  0.0062,  0.1766, -0.0049,  0.0060,  0.0848, -0.0733,\n",
       "                        0.0310,  0.0682,  0.1656, -0.0051, -0.0700,  0.0230,  0.1556,  0.1181,\n",
       "                        0.1604,  0.0165,  0.1670,  0.0256,  0.1723, -0.0251,  0.0231,  0.1918,\n",
       "                        0.0003,  0.0688, -0.0796,  0.0889,  0.1414,  0.0748])),\n",
       "              ('l2.weight',\n",
       "               tensor([[ 0.1304, -0.2885, -0.1455, -0.2538, -0.2327, -0.0839, -0.3131, -0.0400,\n",
       "                         0.0260, -0.0151, -0.1351, -0.0588, -0.1855,  0.1194, -0.1814,  0.7055,\n",
       "                        -0.2971, -0.1744, -0.2412,  0.0329, -0.3201, -0.9173, -0.2253, -0.0043,\n",
       "                         0.7019, -0.3861,  0.1303,  0.5082,  0.8775, -0.3308],\n",
       "                       [-0.1051,  0.4762, -0.1352,  0.1635, -0.2801, -0.1216,  0.5454, -0.1503,\n",
       "                         0.9049,  0.4687,  0.1911, -0.0269, -0.4079, -0.1522,  0.4167, -0.3204,\n",
       "                         0.4735, -0.0795, -0.5681,  0.1661,  0.2968,  0.1185,  0.3037, -0.2229,\n",
       "                        -1.0052, -0.0545, -0.1354,  0.1983, -0.6541, -0.1478],\n",
       "                       [ 0.0332,  0.0706, -0.0025,  1.1350,  1.0402,  0.3634, -0.5327, -0.1552,\n",
       "                         0.1709, -0.3519, -0.2950, -0.0367, -0.1942, -0.6124, -0.1813, -0.7731,\n",
       "                        -0.0879, -0.0744, -0.5621,  0.0252, -0.4541, -0.1963,  0.4618,  0.0071,\n",
       "                        -0.0290,  0.3459, -0.0810,  0.1768, -0.0799, -0.3126],\n",
       "                       [ 0.0739, -0.4142, -0.0645, -0.1620,  0.4751,  0.5132,  0.1312,  0.0240,\n",
       "                        -0.6319,  0.0547, -0.2875, -0.2347,  0.4412,  0.5164, -0.5585, -0.6186,\n",
       "                        -0.2872, -0.1730, -0.0602, -0.1702, -0.2623,  1.0090, -0.3368, -0.3774,\n",
       "                         0.3004,  0.2717,  0.0957,  0.3489, -0.5686, -0.1834],\n",
       "                       [ 0.1661, -0.1137,  0.1617, -0.5360, -0.2159, -0.1247,  0.6241,  0.1471,\n",
       "                         0.5345,  0.0194,  0.2159,  0.0698, -0.0146, -0.0352,  0.8274, -0.0265,\n",
       "                        -0.3916, -0.1798,  0.4217, -0.1326,  0.7453, -0.9234, -0.0900,  0.4316,\n",
       "                         0.1979, -0.0591,  0.1591, -0.7199,  0.0455,  0.1590],\n",
       "                       [ 0.1359,  0.3433, -0.0196,  0.2770, -0.1270, -0.0650, -0.3938, -0.0436,\n",
       "                        -0.7847, -0.1176, -0.5264,  0.0289, -0.5094,  0.3881,  0.4123,  0.5987,\n",
       "                         0.2068, -0.0575,  0.2344, -0.1783, -0.2874,  0.6242, -0.0568, -0.2374,\n",
       "                         0.6127, -0.4726,  0.0760, -0.6226, -0.6796,  0.0943],\n",
       "                       [ 0.1546, -0.4080, -0.0109, -0.1301, -0.1651,  0.0627, -0.2663,  0.1734,\n",
       "                        -0.0982, -0.0678, -0.1540, -0.1369, -0.2100,  0.8428, -0.1236,  0.1660,\n",
       "                         0.6658, -0.1675, -0.3697, -0.1444, -0.0939, -0.3362,  0.6905,  0.6510,\n",
       "                        -0.3323,  0.1199, -0.1198, -0.5208,  0.4064,  0.2282],\n",
       "                       [-0.0098,  0.5466,  0.1393, -0.4100,  0.7723, -0.2436, -0.1512,  0.0540,\n",
       "                        -0.3990,  0.1570,  0.7089, -0.2461,  0.4620, -0.3744, -0.6250,  0.2312,\n",
       "                        -0.3391,  0.2096,  0.2776,  0.0828,  0.5999, -0.1520, -0.0287,  0.2111,\n",
       "                         0.1868, -0.0168, -0.0055, -0.4361, -0.2135, -0.2975],\n",
       "                       [-0.0469, -0.6261, -0.1337,  0.3974, -0.3505, -0.2170,  0.1470,  0.1683,\n",
       "                         0.5362, -0.1797,  0.0690,  0.3373,  0.0616, -0.0573, -0.5049,  0.1870,\n",
       "                         0.0163,  0.0797,  0.4787, -0.0743, -0.4190,  0.3968, -0.2219, -0.1485,\n",
       "                        -0.4061,  0.4759, -0.0444, -0.0811,  0.4874,  0.2258],\n",
       "                       [ 0.0645,  0.3925,  0.0420, -0.6511, -0.8553,  0.1516, -0.3230, -0.0976,\n",
       "                        -0.1309, -0.1182,  0.1477,  0.0816,  0.3041, -0.6950, -0.0737,  0.1786,\n",
       "                        -0.2023,  0.1529,  0.1912, -0.0816,  0.0316,  0.7556, -0.1725, -0.5281,\n",
       "                        -0.1378, -0.5765, -0.0595,  0.9439,  0.0221,  0.5533]])),\n",
       "              ('l2.bias',\n",
       "               tensor([ 0.1568, -0.0485,  0.2748, -0.0336, -0.1602,  0.0261,  0.0113,  0.0623,\n",
       "                        0.1040, -0.0730]))]),\n",
       " 'opt_parameter': {'state': {0: {'momentum_buffer': None},\n",
       "   1: {'momentum_buffer': None},\n",
       "   2: {'momentum_buffer': None},\n",
       "   3: {'momentum_buffer': None}},\n",
       "  'param_groups': [{'lr': 0.03,\n",
       "    'momentum': 0,\n",
       "    'dampening': 0,\n",
       "    'weight_decay': 0,\n",
       "    'nesterov': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'differentiable': False,\n",
       "    'params': [0, 1, 2, 3]}]},\n",
       " 'val_loss': 0.13023250255112848}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0f42b-5503-4971-a4e3-70c50dfceb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
