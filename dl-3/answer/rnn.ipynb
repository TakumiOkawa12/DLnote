{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4dc0c45-f7cb-46ad-8e2a-40264f47ca21",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59731d59-f5d6-436a-9e04-e5144fccaaeb",
   "metadata": {},
   "source": [
    "### RNNスクラッチ実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35510db6-ef34-4581-867f-b20b64f2529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c28f46d-709e-4975-bbed-a7a8ceb98686",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNN:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # pytorchのnn.RNNの重みとバイアスの初期値に合わせる ~U(-1/√hidden_size, 1/√hidden_size)\n",
    "        init_range = 1.0/math.sqrt(hidden_size)\n",
    "        self.W_in = torch.empty(hidden_size, input_size).uniform_(-init_range, init_range)\n",
    "        self.W_h = torch.empty(hidden_size, hidden_size).uniform_(-init_range, init_range)\n",
    "\n",
    "        self.b_in = torch.empty(hidden_size).uniform_(-init_range, init_range)\n",
    "        self.b_h = torch.empty(hidden_size).uniform_(-init_range, init_range)\n",
    "        \n",
    "    def forward(self, input, h_0=None):\n",
    "        # input（batch firstを想定）: [batch_size, seq_len, input_size]\n",
    "        batch_size, seq_len, _ = input.size()\n",
    "\n",
    "        if h_0 is None:\n",
    "            h_0 = torch.zeros(1, batch_size, self.hidden_size)#.to(device)\n",
    "\n",
    "        h = h_0 # [1, batch_size, hidden_size]\n",
    "        outputs = []\n",
    "        for i in range(seq_len):\n",
    "            # [batch_size, hidden_size]\n",
    "            h = torch.tanh(input[:, i]@self.W_in.T + self.b_in + h.squeeze(0)@self.W_h.T + self.b_h)\n",
    "            outputs.append(h.unsqueeze(1))# [batch_size, hidden_size] -> # [batch_size, 1, hidden_size]\n",
    "        output_seq = torch.cat(outputs, dim=1)\n",
    "        h_n = h.unsqueeze(0) # [batch_size, hidden_size] -> [1, batch_size, hidden_size]\n",
    "\n",
    "        return output_seq, h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ee483c-1565-4902-9d9d-0768921b171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_size = 3\n",
    "batch_size = 8\n",
    "seq_len = 5\n",
    "\n",
    "# サンプルのTensor\n",
    "input_tensor = torch.randn(batch_size, seq_len, input_size)\n",
    "rnn = myRNN(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8028076d-f927-4d59-bd05-9fbc101e5729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc3009e5-9a7c-4245-acfa-0376beb074eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_seq, h_n = rnn.forward(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f873e335-091e-457a-b12b-75058184b118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e867c2-a5d6-455d-b997-d200ccc1e4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30cb7eb-d1e8-4a37-a5ca-66d74cf158f6",
   "metadata": {},
   "source": [
    "### RNNモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5866d21-e150-4817-8ba0-57c59bd1e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class myRNNModel:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.rnn = myRNN(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_seq, h_n = self.rnn.forward(x)\n",
    "        # output_seq: [batch_size, seq_len, hidden_size]\n",
    "        # h_n: [1, batch_size, hidden_size]\n",
    "        out = self.fc(h_n.squeeze(0))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "616b0837-f952-4b93-95d5-5f7985c5f631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size = 2 # ２クラス問題\n",
    "model = myRNNModel(input_size, hidden_size, output_size)\n",
    "out = model.forward(input_tensor)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689a4085-b2ba-4dcd-b169-2cb2ea355ae3",
   "metadata": {},
   "source": [
    "### nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1ed4951-ac92-49b0-a3d7-d558fc85a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_seq, h_n = self.rnn(x)\n",
    "        # output_seq: [batch_size, seq_len, hidden_size]\n",
    "        # h_n: [1, batch_size, hidden_size]\n",
    "        # out = self.fc(h_n.squeeze(0))\n",
    "        out = self.fc(output_seq[:, -1, :]) #[batch_size, 1, hidden_size]\n",
    "        # NER: (many to many)\n",
    "        # out = self.fc(output_seq)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07011750-db85-41fc-b6e5-c119906ccb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 10\n",
    "hidden_size = 3\n",
    "batch_size = 8\n",
    "seq_len = 5\n",
    "model = RNNModel(input_size, hidden_size, output_size)\n",
    "out = model(input_tensor)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddef2576-fe4f-44e5-9f38-b10d63e75c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0: torch.Size([3, 10])\n",
      "rnn.weight_hh_l0: torch.Size([3, 3])\n",
      "rnn.bias_ih_l0: torch.Size([3])\n",
      "rnn.bias_hh_l0: torch.Size([3])\n",
      "fc.weight: torch.Size([2, 3])\n",
      "fc.bias: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8bb57-8cac-4eed-b92e-c90777f84ff6",
   "metadata": {},
   "source": [
    "### RNN Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b18804d-90ca-4bdb-9eeb-4963b7d893b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNN:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        init_range = 1.0/math.sqrt(hidden_size)\n",
    "        self.W_in = torch.empty(hidden_size, input_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
    "        self.W_h = torch.empty(hidden_size, hidden_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
    "\n",
    "        self.b_in = torch.empty(hidden_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
    "        self.b_h = torch.empty(hidden_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
    "        \n",
    "    def forward(self, input, h_0=None):\n",
    "        # input: [batch_size, seq_len, input_size]\n",
    "        self.input = input\n",
    "        self.h_0 = h_0\n",
    "        batch_size, self.seq_len, _ = input.size()\n",
    "\n",
    "        if h_0 is None:\n",
    "            self.h_0 = torch.zeros(1, batch_size, self.hidden_size)#.to(device)\n",
    "\n",
    "        h = self.h_0 # [1, batch_size, hidden_size]\n",
    "        outputs = []\n",
    "        for i in range(self.seq_len):\n",
    "            # [batch_size, hidden_size]\n",
    "            h = torch.tanh(input[:, i]@self.W_in.T + self.b_in + h.squeeze(0)@self.W_h.T + self.b_h)\n",
    "            outputs.append(h.unsqueeze(1))# [batch_size, hidden_size] -> # [batch_size, 1, hidden_size]\n",
    "        self.output_seq = torch.cat(outputs, dim=1)\n",
    "        h_n = h.unsqueeze(0) # [batch_size, hidden_size] -> [1, batch_size, hidden_size]\n",
    "\n",
    "        return self.output_seq, h_n\n",
    "\n",
    "    def backward(self, out_grad):\n",
    "\n",
    "        self.grad_W_in_list = []\n",
    "        self.grad_W_h_list = []\n",
    "        self.grad_b_in_list = []\n",
    "        self.grad_b_h_list = []\n",
    "\n",
    "        self.grad_h_list = []\n",
    "        self.grad_h_tanh_list = []\n",
    "\n",
    "        # 勾配の初期化\n",
    "        grad_W_in = torch.zeros_like(self.W_in)\n",
    "        grad_W_h = torch.zeros_like(self.W_h)\n",
    "        grad_b_in = torch.zeros_like(self.b_in)\n",
    "        grad_b_h = torch.zeros_like(self.b_h)\n",
    "        grad_h = torch.zeros_like(self.h_0)\n",
    "\n",
    "        # 各ステップの隠れ状態の勾配を初期化\n",
    "        grad_output_seq = torch.zeros_like(self.output_seq) # [batch_size, seq_len, hidden_size] \n",
    "        grad_output_seq[:, -1, :] = out_grad\n",
    "\n",
    "        # 各ステップにおける勾配を計算\n",
    "        for i in reversed(range(self.seq_len)):\n",
    "\n",
    "            # tanhの微分 (dh*(1-dh^2))\n",
    "            grad_h_tanh = grad_output_seq[:, i] * (1 - self.output_seq[:, i].pow(2))\n",
    "            grad_W_in += torch.sum(grad_h_tanh.unsqueeze(2)*self.input[:, i].unsqueeze(1), dim=0)\n",
    "            grad_b_in += torch.sum(grad_h_tanh, dim=0)\n",
    "            grad_b_h += torch.sum(grad_h_tanh, dim=0)\n",
    "            grad_h = grad_h_tanh @ self.W_h\n",
    "            \n",
    "\n",
    "            if i != 0:\n",
    "                grad_output_seq[:, i-1] = grad_h\n",
    "                # self.output_seqを使って計算\n",
    "                grad_W_h += torch.sum(grad_h_tanh.unsqueeze(2)*self.output_seq[:, i-1].unsqueeze(1), dim=0)\n",
    "            else:\n",
    "                # h_0を使って計算\n",
    "                grad_W_h += torch.sum(grad_h_tanh.unsqueeze(2)*self.h_0.squeeze(0).unsqueeze(1), dim=0)           \n",
    "            # 勾配を保持\n",
    "            self.grad_W_in_list.append(grad_W_in.clone())\n",
    "            self.grad_W_h_list.append(grad_W_h.clone())\n",
    "            self.grad_b_in_list.append(grad_b_in.clone())\n",
    "            self.grad_b_h_list.append(grad_b_h.clone())\n",
    "            self.grad_h_list.append(grad_h.clone())\n",
    "            self.grad_h_tanh_list.append(grad_h_tanh.clone())\n",
    "\n",
    "        # self.W_in -= grad_W_in\n",
    "\n",
    "class myRNNModel:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.rnn = myRNN(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_seq, self.h_n = self.rnn.forward(x)\n",
    "        # output_seq: [batch_size, seq_len, hidden_size]\n",
    "        # h_n: [1, batch_size, hidden_size]\n",
    "        out = self.fc(self.h_n.squeeze(0))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5324e7aa-1ed3-4a46-ab21-3edf69c1c686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autograd Gradient - W_in: tensor([[-0.1744,  0.0524,  0.0822],\n",
      "        [-0.1582,  0.0526,  0.0485]])\n",
      "Manual Gradient - W_in: tensor([[-0.1744,  0.0524,  0.0822],\n",
      "        [-0.1582,  0.0526,  0.0485]], grad_fn=<CloneBackward0>)\n",
      "======================\n",
      "Autograd Gradient - W_h: tensor([[-0.0527,  0.0328],\n",
      "        [-0.0537,  0.0321]])\n",
      "Manual Gradient - W_h: tensor([[-0.0527,  0.0328],\n",
      "        [-0.0537,  0.0321]], grad_fn=<CloneBackward0>)\n",
      "======================\n",
      "Autograd Gradient - b_in: tensor([-0.1149, -0.1115])\n",
      "Manual Gradient - b_in: tensor([-0.1149, -0.1115], grad_fn=<CloneBackward0>)\n",
      "======================\n",
      "Autograd Gradient - b_h: tensor([-0.1149, -0.1115])\n",
      "Manual Gradient - b_h: tensor([-0.1149, -0.1115], grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# backwardのテスト\n",
    "input_size = 3\n",
    "hidden_size = 2\n",
    "batch_size = 3\n",
    "seq_len = 5\n",
    "\n",
    "# 入力データと正解ラベルの定義\n",
    "input_tensor = torch.randn(batch_size, seq_len, input_size)\n",
    "target = torch.tensor([0]*batch_size)\n",
    "\n",
    "# モデルのインスタンス作成\n",
    "model = myRNNModel(input_size, hidden_size, output_size)\n",
    "# forward\n",
    "output = model.forward(input_tensor)\n",
    "\n",
    "# 損失関数の定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 損失計算\n",
    "loss = criterion(output, target)\n",
    "# 出力層の勾配計算\n",
    "out_grad = torch.autograd.grad(loss, model.h_n, retain_graph=True)[0]\n",
    "# スクラッチのbackward\n",
    "model.rnn.backward(out_grad)\n",
    "# autograd\n",
    "loss.backward()\n",
    "\n",
    "print(\"Autograd Gradient - W_in:\", model.rnn.W_in.grad)\n",
    "print(\"Manual Gradient - W_in:\", model.rnn.grad_W_in_list[-1])\n",
    "print(\"======================\")\n",
    "print(\"Autograd Gradient - W_h:\", model.rnn.W_h.grad)\n",
    "print(\"Manual Gradient - W_h:\", model.rnn.grad_W_h_list[-1])\n",
    "print(\"======================\")\n",
    "print(\"Autograd Gradient - b_in:\", model.rnn.b_in.grad)\n",
    "print(\"Manual Gradient - b_in:\", model.rnn.grad_b_in_list[-1])\n",
    "print(\"======================\")\n",
    "print(\"Autograd Gradient - b_h:\", model.rnn.b_h.grad)\n",
    "print(\"Manual Gradient - b_h:\", model.rnn.grad_b_h_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a17fc00-0c57-455e-8b4a-a94ea3dff5c5",
   "metadata": {},
   "source": [
    "#### 外積の計算の例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b1e406d-1221-4004-b658-f1ad9670be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "b = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5da22c48-8809-4b7b-af22-556c7698e711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25a316a3-ea82-4489-919c-c5203294d2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae08c2f-73de-444c-bc44-493689a25f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1, 2, 3],\n",
       "         [2, 4, 6]]),\n",
       " tensor([[12, 15, 18],\n",
       "         [16, 20, 24]]),\n",
       " tensor([[35, 40, 45],\n",
       "         [42, 48, 54]])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# リスト内包表記で一つずつ処理\n",
    "outer_product_list  = [torch.ger(a_row, b_row) for a_row, b_row in zip(a, b)]\n",
    "outer_product_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aed82c87-cc37-426a-9f8b-e7fe47c0265a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 2,  4,  6]],\n",
       "\n",
       "        [[12, 15, 18],\n",
       "         [16, 20, 24]],\n",
       "\n",
       "        [[35, 40, 45],\n",
       "         [42, 48, 54]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 次元を拡張することで一発で計算\n",
    "a.unsqueeze(2) * b.unsqueeze(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
