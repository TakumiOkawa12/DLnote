{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025e26e3-1714-40d0-b8a2-6b6087284f58",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f03e8a-3be5-4066-9822-e997d1eb600b",
   "metadata": {},
   "source": [
    "## RNN forward スクラッチ実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74428754-9b57-4411-beb6-a3c47ad8f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a223852-b97d-4050-b3cf-0802d37c902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNN:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.hidden_size = hidden_size\n",
    "        init_range = 1.0 / math.sqrt(hidden_size)\n",
    "        self.W_in = torch.empty(hidden_size, input_size).uniform_(-init_range, init_range) # .uniform_の「_」はtorchを上書きするという意味\n",
    "        self.W_h = torch.empty(hidden_size, hidden_size).uniform_(-init_range, init_range)\n",
    "\n",
    "        self.b_in = torch.empty(hidden_size).uniform_(-init_range, init_range)\n",
    "        self.b_h = torch.empty(hidden_size).uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, input, h_0 = None):\n",
    "        # 埋め込みベクトルが入力 [batch_size, seq_len, input_size]を想定\n",
    "        batch_size, seq_len, _ = input.size()\n",
    "\n",
    "        if h_0 is None:\n",
    "            h_0 = torch.zeros(1, batch_size, self.hidden_size)\n",
    "        h = h_0\n",
    "        outputs = []\n",
    "        for i in range(seq_len):\n",
    "            h = torch.tanh(input[:, i]@self.W_in.T + self.b_in + h.squeeze(0)@self.W_h.T + self.b_h) # [batch_size, hidden_size]\n",
    "            outputs.append(h.unsqueeze(1)) # [batch_size, 1, hidden_size]\n",
    "        output_seq = torch.cat(outputs, dim = 1)\n",
    "        h_n = h.unsqueeze(0)\n",
    "\n",
    "        return output_seq, h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04ca11de-8c81-48e3-bfb8-94ee9563adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 1, 8)\n",
    "x2 = torch.randn(5,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fe133ed-0938-474a-8d09-697f3beb6432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0218,  0.9922, -0.2399, -1.1270,  0.2945,  0.8130, -0.2159,\n",
       "          -0.5460]],\n",
       "\n",
       "        [[ 0.4150,  0.4166, -2.0738,  0.3873,  0.8671, -0.3171, -1.0317,\n",
       "          -0.2121]],\n",
       "\n",
       "        [[ 0.6203,  1.5436,  0.6842, -0.4510,  0.9774, -0.4703,  1.1409,\n",
       "          -0.0494]],\n",
       "\n",
       "        [[ 1.2131, -0.0858, -2.9257, -0.4792,  0.1307, -1.0303,  0.2659,\n",
       "          -0.6366]],\n",
       "\n",
       "        [[ 0.1213, -0.9121, -0.3683,  0.5056, -0.2147, -1.6706, -1.1620,\n",
       "           1.8605]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77968b14-b97f-4fc1-b64c-536724bb700a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9050,  1.1296, -1.2857,  0.4050, -0.2830,  0.4128,  0.5930,  0.9919],\n",
       "        [-0.9388, -0.2263, -0.3448,  1.0541, -1.5921, -1.2072, -0.4160,  0.3614],\n",
       "        [ 1.1878, -0.2560,  0.1291,  0.1409,  0.6517,  1.3268,  1.3561,  0.4439],\n",
       "        [ 1.7305, -0.8819, -1.0847, -0.9024, -1.4085, -1.8254, -0.7930, -0.0320],\n",
       "        [ 1.1730, -0.4159,  2.3209,  0.9216, -0.6664,  1.7733,  1.0118, -0.3913]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf7cdd8a-8101-4b1b-abeb-62739c3f48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_size = 3\n",
    "batch_size = 8\n",
    "seq_len = 5\n",
    "input_tensor = torch.randn(batch_size, seq_len, input_size)\n",
    "rnn = myRNN(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3be5fae-8dd1-4902-8b22-59adaee87d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_seq, h_n = rnn.forward(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b96f4f52-d3b1-4da7-a5f5-029f8830f1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7472e5ce-904c-498a-a5a4-f3a311ee794a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287896c5-5b26-4fc9-adc1-c89857fc5b01",
   "metadata": {},
   "source": [
    "## RNNモデルの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0865bab7-a08c-4fe8-9c70-197320742da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        init_range = 1.0 / math.sqrt(hidden_size)\n",
    "        self.W_in = torch.empty(hidden_size, input_size).uniform_(-init_range, init_range) # .uniform_の「_」はtorchを上書きするという意味\n",
    "        self.W_h = torch.empty(hidden_size, hidden_size).uniform_(-init_range, init_range)\n",
    "\n",
    "        self.b_in = torch.empty(hidden_size).uniform_(-init_range, init_range)\n",
    "        self.b_h = torch.empty(hidden_size).uniform_(-init_range, init_range)\n",
    "        self.output_linear = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, input, h_0 = None):\n",
    "        # 埋め込みベクトルが入力 [batch_size, seq_len, input_size]を想定\n",
    "        batch_size, seq_len, _ = input.size()\n",
    "\n",
    "        if h_0 is None:\n",
    "            h_0 = torch.zeros(1, batch_size, self.hidden_size)\n",
    "        h = h_0\n",
    "        outputs = []\n",
    "        for i in range(seq_len):\n",
    "            h = torch.tanh(input[:, i]@self.W_in.T + self.b_in + h.squeeze(0)@self.W_h.T + self.b_h) # [batch_size, hidden_size]\n",
    "            outputs.append(h.unsqueeze(1)) # [batch_size, 1, hidden_size]\n",
    "        output_seq = torch.cat(outputs, dim = 1) # [batch_size, seq_len, hidden_size]\n",
    "        h_n = h.unsqueeze(0) # [1, batch_size, hidden_size]\n",
    "        output = self.output_linear(h_n.squeeze(0))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28cbf8cd-0f57-4c1c-8dd0-5f21a8ecc905",
   "metadata": {},
   "outputs": [],
   "source": [
    "myrnnmodel = myRNNModel(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ec0a6f8-f2ef-4e7a-b657-131bb3c3b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = myrnnmodel.forward(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fa6d8f8-6c20-460a-82f5-992c30b4a00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf815ecc-fc13-4e31-a2be-b5a088b5bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNNModel:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.rnn = myRNN(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_seq, h_n = self.rnn.forward(x)\n",
    "        # output_seq: [batch_size, seq_len, hidden_size]\n",
    "        # h_n: [1, batch_size, hidden_size]\n",
    "        out = self.fc(h_n.squeeze(0))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25be4c86-dbc1-48b1-9595-f09ec96ae0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size = 2 # ２クラス問題\n",
    "model = myRNNModel(input_size, hidden_size, output_size)\n",
    "out = model.forward(input_tensor)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247693dc-77ee-457d-99f0-debf9199ede5",
   "metadata": {},
   "source": [
    "## nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ea08149-5e88-4894-9bd8-28a8e34fa3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_seq, h_n = self.rnn(x)\n",
    "        # output_seq: [batch_size, seq_len, hidden_size]\n",
    "        # h_n: [1, batch_size, hidden_size]\n",
    "        out = self.fc(h_n.squeeze(0)) # nn.Linearは入力物の一番最後の次元を見てる\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02cdf5e2-288f-450a-adef-9e109a83f278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size = 2 # ２クラス問題\n",
    "model = myRNNModel(input_size, hidden_size, output_size)\n",
    "out = model(input_tensor)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28c479fe-f4a5-4238-af03-760eeb58fe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0: torch.Size([3, 10])\n",
      "rnn.weight_hh_l0: torch.Size([3, 3])\n",
      "rnn.bias_ih_l0: torch.Size([3])\n",
      "rnn.bias_hh_l0: torch.Size([3])\n",
      "fc.weight: torch.Size([2, 3])\n",
      "fc.bias: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'{name}: {param.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276795f-a7c7-4704-831c-2607c9d8f70b",
   "metadata": {},
   "source": [
    "## RNN Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f6dd72c-418d-4770-9d56-d3f644726999",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNN:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        init_range = 1.0/math.sqrt(hidden_size)\n",
    "        self.W_in = torch.empty(hidden_size, input_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
    "        self.W_h = torch.empty(hidden_size, hidden_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
    "\n",
    "        self.b_in = torch.empty(hidden_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
    "        self.b_h = torch.empty(hidden_size).uniform_(-init_range, init_range).requires_grad_(True)\n",
    "        \n",
    "    def forward(self, input, h_0=None):\n",
    "        # input: [batch_size, seq_len, input_size]\n",
    "        self.input = input\n",
    "        self.h_0 = h_0\n",
    "        batch_size, self.seq_len, _ = input.size()\n",
    "\n",
    "        if h_0 is None:\n",
    "            self.h_0 = torch.zeros(1, batch_size, self.hidden_size)#.to(device)\n",
    "\n",
    "        h = self.h_0 # [1, batch_size, hidden_size]\n",
    "        outputs = []\n",
    "        for i in range(self.seq_len):\n",
    "            # [batch_size, hidden_size]\n",
    "            h = torch.tanh(input[:, i]@self.W_in.T + self.b_in + h.squeeze(0)@self.W_h.T + self.b_h)\n",
    "            outputs.append(h.unsqueeze(1))# [batch_size, hidden_size] -> # [batch_size, 1, hidden_size]\n",
    "        self.output_seq = torch.cat(outputs, dim=1)\n",
    "        h_n = h.unsqueeze(0) # [batch_size, hidden_size] -> [1, batch_size, hidden_size]\n",
    "\n",
    "        return self.output_seq, h_n\n",
    "\n",
    "    def backward(self, out_grad):\n",
    "\n",
    "        self.grad_W_in_list = []\n",
    "        self.grad_W_h_list = []\n",
    "        self.grad_b_in_list = []\n",
    "        self.grad_b_h_list = []\n",
    "\n",
    "        self.grad_h_list = []\n",
    "        self.grad_h_tanh_list = []\n",
    "\n",
    "        # 勾配の初期化\n",
    "        grad_W_in = torch.zeros_like(self.W_in)\n",
    "        grad_W_h = torch.zeros_like(self.W_h)\n",
    "        grad_b_in = torch.zeros_like(self.b_in)\n",
    "        grad_b_h = torch.zeros_like(self.b_h)\n",
    "        grad_h = torch.zeros_like(self.h_0)\n",
    "\n",
    "        # 各ステップの隠れ状態の勾配を初期化\n",
    "        grad_output_seq = torch.zeros_like(self.output_seq) # [batch_size, seq_len, hidden_size] \n",
    "        grad_output_seq[:, -1, :] = out_grad\n",
    "\n",
    "        # 各ステップにおける勾配を計算\n",
    "        for i in reversed(range(self.seq_len)):\n",
    "\n",
    "            # tanhの微分 (dh*(1-dh^2))\n",
    "            grad_h_tanh = grad_output_seq[:, i] * (1 - self.output_seq[:, i].pow(2))\n",
    "            grad_W_in += torch.sum(grad_h_tanh.unsqueeze(2)*self.input[:, i].unsqueeze(1), dim=0)\n",
    "            grad_b_in += torch.sum(grad_h_tanh, dim=0)\n",
    "            grad_b_h += torch.sum(grad_h_tanh, dim=0)\n",
    "            grad_h = grad_h_tanh @ self.W_h\n",
    "\n",
    "\n",
    "            if i != 0:\n",
    "                grad_output_seq[:, i-1] = grad_h\n",
    "                # self.output_seqを使って計算\n",
    "                grad_W_h += torch.sum(grad_h_tanh.unsqueeze(2)*self.output_seq[:, i-1].unsqueeze(1), dim=0)\n",
    "            else:\n",
    "                # h_0を使って計算\n",
    "                grad_W_h += torch.sum(grad_h_tanh.unsqueeze(2)*self.h_0.squeeze(0).unsqueeze(1), dim=0)           \n",
    "            # 勾配を保持\n",
    "            self.grad_W_in_list.append(grad_W_in.clone())\n",
    "            self.grad_W_h_list.append(grad_W_h.clone())\n",
    "            self.grad_b_in_list.append(grad_b_in.clone())\n",
    "            self.grad_b_h_list.append(grad_b_h.clone())\n",
    "            self.grad_h_list.append(grad_h.clone())\n",
    "            self.grad_h_tanh_list.append(grad_h_tanh.clone())\n",
    "\n",
    "        # self.W_in -= grad_W_in\n",
    "\n",
    "class myRNNModel:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.rnn = myRNN(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_seq, self.h_n = self.rnn.forward(x)\n",
    "        # output_seq: [batch_size, seq_len, hidden_size]\n",
    "        # h_n: [1, batch_size, hidden_size]\n",
    "        out = self.fc(self.h_n.squeeze(0))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40a2e461-87ac-4803-b409-8d0ba0b6c1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autograd Gradient - W_in: tensor([[ 0.1289,  0.0223, -0.0584],\n",
      "        [ 0.2189,  0.0159, -0.0840]])\n",
      "Manual Gradient - W_in: tensor([[ 0.1289,  0.0223, -0.0584],\n",
      "        [ 0.2189,  0.0159, -0.0840]], grad_fn=<CloneBackward0>)\n",
      "======================\n",
      "Autograd Gradient - W_h: tensor([[ 0.0051, -0.0151],\n",
      "        [ 0.0381,  0.0359]])\n",
      "Manual Gradient - W_h: tensor([[ 0.0051, -0.0151],\n",
      "        [ 0.0381,  0.0359]], grad_fn=<CloneBackward0>)\n",
      "======================\n",
      "Autograd Gradient - b_in: tensor([-0.0425, -0.2699])\n",
      "Manual Gradient - b_in: tensor([-0.0425, -0.2699], grad_fn=<CloneBackward0>)\n",
      "======================\n",
      "Autograd Gradient - b_h: tensor([-0.0425, -0.2699])\n",
      "Manual Gradient - b_h: tensor([-0.0425, -0.2699], grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# backwardのテスト\n",
    "input_size = 3\n",
    "hidden_size = 2\n",
    "batch_size = 3\n",
    "seq_len = 5\n",
    "\n",
    "# 入力データと正解ラベルの定義\n",
    "input_tensor = torch.randn(batch_size, seq_len, input_size)\n",
    "target = torch.tensor([0]*batch_size)\n",
    "\n",
    "# モデルのインスタンス作成\n",
    "model = myRNNModel(input_size, hidden_size, output_size)\n",
    "# forward\n",
    "output = model.forward(input_tensor)\n",
    "\n",
    "# 損失関数の定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 損失計算\n",
    "loss = criterion(output, target)\n",
    "# 出力層の勾配計算\n",
    "out_grad = torch.autograd.grad(loss, model.h_n, retain_graph=True)[0]\n",
    "# スクラッチのbackward\n",
    "model.rnn.backward(out_grad)\n",
    "# autograd\n",
    "loss.backward()\n",
    "\n",
    "print(\"Autograd Gradient - W_in:\", model.rnn.W_in.grad)\n",
    "print(\"Manual Gradient - W_in:\", model.rnn.grad_W_in_list[-1])\n",
    "print(\"======================\")\n",
    "print(\"Autograd Gradient - W_h:\", model.rnn.W_h.grad)\n",
    "print(\"Manual Gradient - W_h:\", model.rnn.grad_W_h_list[-1])\n",
    "print(\"======================\")\n",
    "print(\"Autograd Gradient - b_in:\", model.rnn.b_in.grad)\n",
    "print(\"Manual Gradient - b_in:\", model.rnn.grad_b_in_list[-1])\n",
    "print(\"======================\")\n",
    "print(\"Autograd Gradient - b_h:\", model.rnn.b_h.grad)\n",
    "print(\"Manual Gradient - b_h:\", model.rnn.grad_b_h_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f0b7da9-875a-43a7-92d5-62a805c53b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5562, -0.2143],\n",
       "         [-0.5922,  0.3486],\n",
       "         [-0.4653,  0.4792]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fab92a-192a-4411-b6d9-b6189449aa8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
